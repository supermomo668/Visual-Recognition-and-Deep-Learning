{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b96597e-2e64-4f33-b4d8-15a1c900766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torch.nn.parameter import Parameter\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pickle as pkl\n",
    "\n",
    "# imports\n",
    "from wsddn import WSDDN\n",
    "from voc_dataset import *\n",
    "import wandb\n",
    "from utils import nms, tensor_to_PIL\n",
    "from PIL import Image, ImageDraw\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68fad5dd-89ca-4b58-99e8-4969dfd0d440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__module__': '__main__', 'parsed_args': Namespace(disp_interval=10, epochs=5, lr=0.0001, lr_decay=0.1, lr_decay_steps=150000, momentum=0.9, use_wandb=False, val_interval=5000, weight_decay=0.0005), 'print_freq': 10, 'eval_freq': 5000, 'epochs': 5, 'lr': 0.0001, 'pretrained': True, 'momentum': 0.9, 'weight_decay': 0.0005, '__dict__': <attribute '__dict__' of 'args' objects>, '__weakref__': <attribute '__weakref__' of 'args' objects>, '__doc__': None}\n"
     ]
    }
   ],
   "source": [
    "# hyper-parameters\n",
    "# ------------\n",
    "parser = argparse.ArgumentParser(description='PyTorch ImageNet Training')\n",
    "parser.add_argument(\n",
    "    '--lr',\n",
    "    default=0.0001,\n",
    "    type=float,\n",
    "    help='Learning rate'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--lr-decay-steps',\n",
    "    default=150000,\n",
    "    type=int,\n",
    "    help='Interval at which the lr is decayed'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--lr-decay',\n",
    "    default=0.1,\n",
    "    type=float,\n",
    "    help='Decay rate of lr'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--momentum',\n",
    "    default=0.9,\n",
    "    type=float,\n",
    "    help='Momentum of optimizer'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--weight-decay',\n",
    "    default=0.0005,\n",
    "    type=float,\n",
    "    help='Weight decay'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--epochs',\n",
    "    default=5,\n",
    "    type=int,\n",
    "    help='Number of epochs'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--val-interval',\n",
    "    default=5000,\n",
    "    type=int,\n",
    "    help='Interval at which to perform validation'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--disp-interval',\n",
    "    default=10,\n",
    "    type=int,\n",
    "    help='Interval at which to perform visualization'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--use-wandb',\n",
    "    default=False,\n",
    "    type=bool,\n",
    "    help='Flag to enable visualization'\n",
    ")\n",
    "\n",
    "class args:\n",
    "    parsed_args = parser.parse_known_args()[0]\n",
    "    #batch_size = parsed_args.batch_size\n",
    "    #workers = parsed_args.workers\n",
    "    print_freq = parsed_args.disp_interval\n",
    "    eval_freq= parsed_args.val_interval\n",
    "    epochs = parsed_args.epochs\n",
    "    lr= parsed_args.lr\n",
    "    #arch = parsed_args.arch\n",
    "    pretrained = True\n",
    "    momentum = parsed_args.momentum\n",
    "    weight_decay = parsed_args.weight_decay\n",
    "    #start_epoch = parsed_args.start_epoch\n",
    "print(args.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e857e6a4-764f-44b3-9aa5-bc66711dacb3",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3587766587.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_8411/3587766587.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Set random seed\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "rand_seed = 1024\n",
    "if rand_seed is not None:\n",
    "    np.random.seed(rand_seed)\n",
    "    torch.manual_seed(rand_seed)\n",
    "\n",
    "# Set output directory\n",
    "output_dir = \"./\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "\n",
    "def calculate_map():\n",
    "    \"\"\"\n",
    "    Calculate the mAP for classification.\n",
    "    \"\"\"\n",
    "    # TODO (Q2.3): Calculate mAP on test set.\n",
    "    # Feel free to write necessary function parameters.\n",
    "    pass\n",
    "\n",
    "\n",
    "def test_model(model, val_loader=None, thresh=0.05):\n",
    "    \"\"\"\n",
    "    Tests the networks and visualizes the detections\n",
    "    :param thresh: Confidence threshold\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        for iter, data in enumerate(val_loader):\n",
    "\n",
    "            # one batch = data for one image\n",
    "            image = data['image']\n",
    "            target = data['label']\n",
    "            wgt = data['wgt']\n",
    "            rois = data['rois']\n",
    "            gt_boxes = data['gt_boxes']\n",
    "            gt_class_list = data['gt_classes']\n",
    "            # TODO (Q2.3): perform forward pass, compute cls_probs\n",
    "            \n",
    "            \n",
    "            # TODO (Q2.3): Iterate over each class (follow comments)\n",
    "            for class_num in range(20):\n",
    "                # get valid rois and cls_scores based on thresh\n",
    "                \n",
    "                # use NMS to get boxes and scores\n",
    "                pass\n",
    "\n",
    "            # TODO (Q2.3): visualize bounding box predictions when required\n",
    "            calculate_map()\n",
    "\n",
    "\n",
    "def train_model(model, train_loader=None, val_loader=None, optimizer=None, args=None):\n",
    "    \"\"\"\n",
    "    Trains the network, runs evaluation and visualizes the detections\n",
    "    \"\"\"\n",
    "    # Initialize training variables\n",
    "    train_loss = 0\n",
    "    step_cnt = 0\n",
    "    for epoch in range(args.epochs):\n",
    "        for iter, data in enumerate(train_loader):\n",
    "\n",
    "            # TODO (Q2.2): get one batch and perform forward pass\n",
    "            # one batch = data for one image\n",
    "            image = data['image']\n",
    "            target = data['label']\n",
    "            wgt = data['wgt']\n",
    "            rois = data['rois']\n",
    "            gt_boxes = data['gt_boxes']\n",
    "            gt_class_list = data['gt_classes']\n",
    "\n",
    "            # TODO (Q2.2): perform forward pass\n",
    "            # take care that proposal values should be in pixels\n",
    "            # Convert inputs to cuda if training on GPU\n",
    "            \n",
    "\n",
    "            # backward pass and update\n",
    "            loss = model.loss\n",
    "            train_loss += loss.item()\n",
    "            step_cnt += 1\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # TODO (Q2.2): evaluate the model every N iterations (N defined in handout)\n",
    "            # Add wandb logging wherever necessary\n",
    "            if iter % args.val_interval == 0 and iter != 0:\n",
    "                model.eval()\n",
    "                ap = test_model(model, val_loader)\n",
    "                print(\"AP \", ap)\n",
    "                model.train()\n",
    "\n",
    "            # TODO (Q2.4): Perform all visualizations here\n",
    "            # The intervals for different things are defined in the handout\n",
    "            \n",
    "\n",
    "    # TODO (Q2.4): Plot class-wise APs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e71508e-6f2d-4501-a436-938f377ccfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Creates dataloaders, network, and calls the trainer\n",
    "    \"\"\"\n",
    "    args = parser.parse_args()\n",
    "    # TODO (Q2.2): Load datasets and create dataloaders\n",
    "    # Initialize wandb logger\n",
    "    train_dataset = None\n",
    "    val_dataset = None\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=1,   # batchsize is one for this implementation\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        sampler=None,\n",
    "        drop_last=True)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        drop_last=True)\n",
    "\n",
    "    # Create network and initialize\n",
    "    net = WSDDN(classes=train_dataset.CLASS_NAMES)\n",
    "    print(net)\n",
    "\n",
    "    if os.path.exists('pretrained_alexnet.pkl'):\n",
    "        pret_net = pkl.load(open('pretrained_alexnet.pkl', 'rb'))\n",
    "    else:\n",
    "        pret_net = model_zoo.load_url(\n",
    "            'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth')\n",
    "        pkl.dump(pret_net,\n",
    "        open('pretrained_alexnet.pkl', 'wb'), pkl.HIGHEST_PROTOCOL)\n",
    "    own_state = net.state_dict()\n",
    "\n",
    "    for name, param in pret_net.items():\n",
    "        print(name)\n",
    "        if name not in own_state:\n",
    "            continue\n",
    "        if isinstance(param, Parameter):\n",
    "            param = param.data\n",
    "        try:\n",
    "            own_state[name].copy_(param)\n",
    "            print('Copied {}'.format(name))\n",
    "        except:\n",
    "            print('Did not find {}'.format(name))\n",
    "            continue\n",
    "\n",
    "    # Move model to GPU and set train mode\n",
    "    net.load_state_dict(own_state)\n",
    "    net.cuda()\n",
    "    net.train()\n",
    "\n",
    "    # TODO (Q2.2): Freeze AlexNet layers since we are loading a pretrained model\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    # TODO (Q2.2): Create optimizer only for network parameters that are trainable\n",
    "    optimizer = None\n",
    "\n",
    "    # Training\n",
    "    train_model(net, train_loader, optimizer, args)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
