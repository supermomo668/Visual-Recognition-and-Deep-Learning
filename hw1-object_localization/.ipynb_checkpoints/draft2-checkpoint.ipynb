{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b96597e-2e64-4f33-b4d8-15a1c900766b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import warnings\n",
    "#warnings.filterwarnings('error')\n",
    "# with warnings.catch_warnings():\n",
    "#     warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "    \n",
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torch.nn.parameter import Parameter\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# imports\n",
    "from wsddn import WSDDN\n",
    "from voc_dataset import *\n",
    "import wandb\n",
    "from utils import nms, tensor_to_PIL\n",
    "from PIL import Image, ImageDraw\n",
    "import sklearn.metrics\n",
    "from utils import *\n",
    "#\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68fad5dd-89ca-4b58-99e8-4969dfd0d440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__module__': '__main__', 'parsed_args': Namespace(disp_interval=10, epochs=5, lr=0.0001, lr_decay=0.1, lr_decay_steps=150000, momentum=0.9, use_wandb=True, val_interval=5000, weight_decay=0.0005), 'batch_size': 1, 'workers': 2, 'disp_interval': 10, 'val_interval': 5000, 'epochs': 5, 'lr': 0.0001, 'use_wandb': True, 'pretrained': True, 'momentum': 0.9, 'weight_decay': 0.0005, '__dict__': <attribute '__dict__' of 'args' objects>, '__weakref__': <attribute '__weakref__' of 'args' objects>, '__doc__': None}\n"
     ]
    }
   ],
   "source": [
    "# hyper-parameters\n",
    "# ------------\n",
    "parser = argparse.ArgumentParser(description='PyTorch ImageNet Training')\n",
    "parser.add_argument(\n",
    "    '--lr',\n",
    "    default=0.0001,\n",
    "    type=float,\n",
    "    help='Learning rate'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--lr-decay-steps',\n",
    "    default=150000,\n",
    "    type=int,\n",
    "    help='Interval at which the lr is decayed'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--lr-decay',\n",
    "    default=0.1,\n",
    "    type=float,\n",
    "    help='Decay rate of lr'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--momentum',\n",
    "    default=0.9,\n",
    "    type=float,\n",
    "    help='Momentum of optimizer'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--weight-decay',\n",
    "    default=0.0005,\n",
    "    type=float,\n",
    "    help='Weight decay'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--epochs',\n",
    "    default=5,\n",
    "    type=int,\n",
    "    help='Number of epochs'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--val-interval',\n",
    "    default=5000,\n",
    "    type=int,\n",
    "    help='Interval at which to perform validation'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--disp-interval',\n",
    "    default=10,\n",
    "    type=int,\n",
    "    help='Interval at which to perform visualization'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--use-wandb',\n",
    "    default=True,\n",
    "    type=bool,\n",
    "    help='Flag to enable visualization'\n",
    ")\n",
    "class args:\n",
    "    parsed_args = parser.parse_known_args()[0]\n",
    "    batch_size = 1\n",
    "    workers = 2\n",
    "    disp_interval = parsed_args.disp_interval\n",
    "    val_interval= parsed_args.val_interval\n",
    "    epochs = parsed_args.epochs\n",
    "    lr= parsed_args.lr\n",
    "    use_wandb = parsed_args.use_wandb\n",
    "    pretrained = True\n",
    "    momentum = parsed_args.momentum\n",
    "    weight_decay = parsed_args.weight_decay\n",
    "    #start_epoch = parsed_args.start_epoch\n",
    "print(args.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7df7a257-5ac3-4d2e-8443-0659f4912a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path:/home/mo/hw/hw1-object_localization/data/VOCdevkit/VOC2007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m3m-m\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mo/hw/hw1-object_localization/wandb/run-20221007_034228-3hpqdreo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/3m-m/vlr-hw1%28task2%29/runs/3hpqdreo\" target=\"_blank\">sweet-night-7</a></strong> to <a href=\"https://wandb.ai/3m-m/vlr-hw1%28task2%29\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "global args\n",
    "# TODO (Q2.2): Load datasets and create dataloaders\n",
    "dataset = VOCDataset('trainval', top_n=300, image_size=512, data_dir='./data/VOCdevkit/VOC2007/')\n",
    "n = len(dataset)\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [int(np.floor(n*0.8)), n-int(np.floor(n*0.8))])\n",
    "train_sampler = torch.utils.data.SubsetRandomSampler(range(len(train_dataset)))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=args.workers,\n",
    "    pin_memory=True,\n",
    "    sampler=train_sampler,\n",
    "    collate_fn=custom_collate_fn_VOC,\n",
    "    drop_last=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=args.workers,\n",
    "    pin_memory=True,\n",
    "    collate_fn=custom_collate_fn_VOC,\n",
    "    drop_last=True)\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "# Initialize wandb logger\n",
    "if args.use_wandb:\n",
    "    wandb.init(project=\"vlr-hw1(task2)\", reinit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e857e6a4-764f-44b3-9aa5-bc66711dacb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "rand_seed = 1024\n",
    "if rand_seed is not None:\n",
    "    np.random.seed(rand_seed)\n",
    "    torch.manual_seed(rand_seed)\n",
    "\n",
    "# Set output directory\n",
    "output_dir = \"./\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "def metric1(output, target):\n",
    "    # TODO (Q1.5): compute metric1\n",
    "    target = target.detach().numpy().astype('int')\n",
    "    output = output.detach().numpy().astype('float')\n",
    "    # get features that aren't all zero\n",
    "    feat_considered = ~np.all(np.concatenate([target, output]), axis=0)\n",
    "    mean_ap = sklearn.metrics.average_precision_score(target[:,feat_considered], output[:,feat_considered], average='samples')\n",
    "    return mean_ap    #[0]\n",
    "\n",
    "def calculate_map(roi_bboxes, box_scores,  gt_classes, gt_bboxes, n_classes=20):\n",
    "    \"\"\"\n",
    "    Calculate the mAP for classification.\n",
    "    #        \n",
    "    \"\"\"\n",
    "    # TODO (Q2.3): Calculate mAP on test set.\n",
    "    # Using IOU to iterate each box for each class\n",
    "    # Compare each iteratively and take Maximum IOU\n",
    "    pred_boxes, gt_boxes = np.asarray(roi_bboxes), np.asarray(gt_bboxes)\n",
    "    box_scores = np.asarray(box_scores)\n",
    "    per_class_iou = np.zeros(n_classes)   # ( 20)\n",
    "    filtered_bboxes = []\n",
    "    cls_labels = []\n",
    "    for class_num in range(20):   # (per class)\n",
    "        gt_class_idx = np.where(np.asarray(gt_classes)==class_num)[0]\n",
    "        pred_class_idx = np.where(np.argmax(np.asarray(roi_bboxes), axis=1)==class_num)[0]\n",
    "        if len(pred_class_idx)==0 or len(gt_class_idx)==0:\n",
    "            per_class_iou[class_num] = 0\n",
    "            continue\n",
    "        pred_class_bbox, gt_class_bbox = pred_boxes[pred_class_idx], gt_boxes[gt_class_idx]\n",
    "        #\n",
    "        bboxes, conf_scores = nms(pred_class_bbox, box_scores[pred_class_idx])\n",
    "        filtered_bboxes.append(bboxes)\n",
    "        cls_labels += [class_num]*len(bboxes)\n",
    "        # iterate each bbox to gt bbox\n",
    "        class_iou = []\n",
    "        for i, pred_box in enumerate(pred_class_bbox):\n",
    "            class_iou.append(np.max([iou(pred_box, gt_box) for gt_box in gt_class_bbox]))\n",
    "        per_class_iou[class_num] = np.array(class_iou).mean()\n",
    "    return per_class_iou, (filtered_bboxes, cls_labels)\n",
    "\n",
    "\n",
    "def test_model(model, val_loader=None, thresh=0.05):\n",
    "    \"\"\"\n",
    "    Tests the networks and visualizes the detections\n",
    "    :param thresh: Confidence threshold\n",
    "    \"\"\"\n",
    "    test_loss = 0\n",
    "    class_id_to_label = dict(enumerate(dataset.CLASS_NAMES))\n",
    "    class_ap_table = wandb.Table(columns=dataset.CLASS_NAMES)\n",
    "    vis_table = wandb.Table(columns=[\"image\", \"prediction\", \"mean AP (over all class)\"])\n",
    "    batch_class_ap = []\n",
    "    #\n",
    "    with torch.no_grad():\n",
    "        batch_ap_by_class = []\n",
    "        for i, data in enumerate(val_loader):\n",
    "            # one batch = data for one image\n",
    "            image = data['image']\n",
    "            target = data['label']\n",
    "            wgt = data['wgt']\n",
    "            rois = data['rois']\n",
    "            gt_boxes = data['gt_boxes']\n",
    "            gt_class = data['gt_classes']\n",
    "            if np.any([len(r)!= 300 for r in rois]):\n",
    "                continue\n",
    "            img_info = dict.fromkeys(np.arange(args.batch_size), {'pred_boxes':[],'pred_cls':[]})\n",
    "            # TODO (Q2.3): perform forward pass, compute cls_probs\n",
    "            box_prob = model(image, rois, target)   # (N, 300, 20)\n",
    "            loss = model.build_loss(box_prob, target)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # TODO (Q2.3): Iterate over each class (follow comments)\n",
    "            #for n in range(args.batch_size):\n",
    "            # Get NMS bboxes\n",
    "            ap_by_class, (pred_boxes, labels) = calculate_map(rois[0], box_prob[0].detach().cpu(),  gt_class[0], gt_boxes[0])\n",
    "            batch_class_ap.append(ap_by_class)\n",
    "            running_mean_ap = np.mean(np.stack(batch_class_ap), axis=0)\n",
    "            class_ap_table.add_data(*running_mean_ap)\n",
    "            # TODO (Q2.3): visualize bounding box predictions when required\n",
    "            if i%args.val_interval==0:\n",
    "                for n, im in enumerate(image):\n",
    "                    gtbbox_img = wandb.Image(im, boxes={\n",
    "                        \"predictions\": {\n",
    "                        \"box_data\": get_box_data(data['gt_classes'][n], data['gt_boxes'][n]),\n",
    "                        \"class_labels\": class_id_to_label,       \n",
    "                        },\n",
    "                    })\n",
    "                    predbbox_img = wandb.Image(im, boxes={\n",
    "                        \"predictions\": {\n",
    "                        \"box_data\": get_box_data(img_info[n]['pred_cls'], img_info[n]['pred_boxes']),\n",
    "                        \"class_labels\": class_id_to_label,       \n",
    "                        },\n",
    "                    })\n",
    "                    vis_table.add_data(gtbbox_img, predbbox_img, np.mean(running_mean_ap)) \n",
    "        wandb.log({\"val/Visuals\": vis_table})\n",
    "        wandb.log({\"AP by Class\": class_ap_table})\n",
    "    return np.nanmean(np.stack(batch_class_ap), axis=0)\n",
    "            \n",
    "\n",
    "\n",
    "def train_model(model, train_loader=None, val_loader=None, optimizer=None, args=None):\n",
    "    \"\"\"\n",
    "    Trains the network, runs evaluation and visualizes the detections\n",
    "    \"\"\"\n",
    "    # Initialize training variables\n",
    "    train_loss = 0\n",
    "    step_cnt = 0\n",
    "    class_id_to_label = dict(enumerate(dataset.CLASS_NAMES))\n",
    "    vis_table = wandb.Table(columns=[\"image\", \"class AP scores\"])\n",
    "    for epoch in range(args.epochs):\n",
    "        for i, data in enumerate(train_loader):\n",
    "            debug=True if (epoch<=3 and i<=1) else False\n",
    "            # TODO (Q2.2): get one batch and perform forward pass\n",
    "            # one batch = data for one image\n",
    "            image = data['image']\n",
    "            target = data['label']\n",
    "            wgt = data['wgt']\n",
    "            rois = data['rois']\n",
    "            gt_boxes = data['gt_boxes']\n",
    "            gt_class = data['gt_classes']\n",
    "            if len(rois[0])!=300:\n",
    "                print(\"Roi length rejected:\", len(rois[0]))\n",
    "                continue\n",
    "            # TODO (Q2.2): perform forward pass\n",
    "            # take care that proposal values should be in pixels\n",
    "            # Convert inputs to cuda if training on GPU\n",
    "            if debug: print(f\"Input shapes: Image {image.size()}; ROIs:{[r.size() for r in rois]}; targets:{target.size()}\")\n",
    "            box_prob = model(image, rois, target)   # (N, 300, 20)\n",
    "            if debug: print(f\"Output shape: {box_prob.size(), torch.sum(torch.isnan(box_prob))}\")\n",
    "            # backward pass and update\n",
    "            if debug: print(f\"Compute loss:\\n{torch.mean(box_prob)}\\n{torch.mean(target)}\")\n",
    "            loss = model.loss\n",
    "            \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            step_cnt += 1\n",
    "            # measure metrics and record loss\n",
    "            #m1 = metric1(torch.sum(box_prob,dim=1).cpu(), target.cpu())\n",
    "            wandb.log(\n",
    "                {'train/loss':train_loss/step_cnt}, #'train/metric1': m1} #,  'train/metric2': m2,}\n",
    "            )\n",
    "            # TODO (Q2.2): evaluate the model every N iterations (N defined in handout)\n",
    "            # Add wandb logging wherever necessary\n",
    "            if i % args.val_interval == 0 and iter != 0:\n",
    "                print(\"Evaluating Model.\")\n",
    "                model.eval()\n",
    "                ap = test_model(model, val_loader)\n",
    "                model.train()\n",
    "            \n",
    "            # TODO (Q2.4): Perform all visualizations here\n",
    "            # The intervals for different things are defined in the handout\n",
    "            if i % args.disp_interval==0:\n",
    "                print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Loss {train_loss:.4f}\\t'.format(\n",
    "                      epoch,\n",
    "                      i,\n",
    "                      len(train_loader),\n",
    "                      train_loss=train_loss/step_cnt,\n",
    "                      #metric1=m1,\n",
    "                      # ap=ap,\n",
    "                  )\n",
    "                )\n",
    "                #\n",
    "            if i%args.disp_interval:\n",
    "                for n, im in enumerate(image):\n",
    "                    input_img = wandb.Image(im, boxes={\n",
    "                        \"predictions\": {\n",
    "                            \"box_data\": get_box_data(data['gt_classes'][n], data['gt_boxes'][n]),\n",
    "                            \"class_labels\": class_id_to_label,       \n",
    "                        },\n",
    "                    })\n",
    "                    vis_table.add_data(input_img, {name:s for name, s in zip(dataset.CLASS_NAMES,ap)})\n",
    "                wandb.log({\"train/Visuals\": vis_table})\n",
    "                # wandb.log({\"AP by Class\": class_ap_table})\n",
    "    \n",
    "    # TODO (Q2.4): Plot class-wise APs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51538713-d7b2-4682-9966-b032a18728aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(train_loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2ca4cbce-d440-4f74-ac0d-3fe5c19c22d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "test_model(net, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edad5f1-5e1b-4286-9b46-342db690f940",
   "metadata": {},
   "source": [
    "<b> Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e92bab62-2caf-4deb-b568-48efab2fe414",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes:['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WSDDN(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=0, dilation=(1, 1), ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=0, dilation=(1, 1), ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU()\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (roi_pool): RoIPool(output_size=(6, 6), spatial_scale=0.0625)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "  )\n",
       "  (score_out): Sequential(\n",
       "    (0): Linear(in_features=4096, out_features=20, bias=True)\n",
       "  )\n",
       "  (bbox_out): Sequential(\n",
       "    (0): Linear(in_features=4096, out_features=20, bias=True)\n",
       "  )\n",
       "  (criterion): BCELoss()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create network and initialize\n",
    "net = WSDDN(classes=dataset.CLASS_NAMES)\n",
    "\n",
    "if os.path.exists('pretrained_alexnet.pkl'):\n",
    "    pret_net = pkl.load(open('pretrained_alexnet.pkl', 'rb'))\n",
    "else:\n",
    "    pret_net = model_zoo.load_url(\n",
    "        'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth')\n",
    "    pkl.dump(pret_net,\n",
    "    open('pretrained_alexnet.pkl', 'wb'), pkl.HIGHEST_PROTOCOL)\n",
    "own_state = net.state_dict()\n",
    "\n",
    "for name, param in pret_net.items():\n",
    "    if name not in own_state:\n",
    "        continue\n",
    "    if isinstance(param, Parameter):\n",
    "        param = param.data\n",
    "    try:\n",
    "        own_state[name].copy_(param)\n",
    "    except:\n",
    "        print('Did not find {}'.format(name))\n",
    "        continue\n",
    "\n",
    "# Move model to GPU and set train mode\n",
    "net.load_state_dict(own_state)\n",
    "net.cuda()\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3e71508e-6f2d-4501-a436-938f377ccfee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO (Q2.2): Freeze AlexNet layers since we are loading a pretrained model\n",
    "for param in net.features.parameters():\n",
    "    param.requires_grad = False\n",
    "# TODO (Q2.2): Create optimizer only for network parameters that are trainable\n",
    "param = []\n",
    "for m in [net.classifier, net.score_out, net.bbox_out]:\n",
    "    param += list(m.parameters())\n",
    "optimizer = torch.optim.SGD(param,\n",
    "                            lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1330cd2-9e4a-4bc4-8c36-d1616c5ca6ec",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start train.\n",
      "Input shapes: Image torch.Size([1, 3, 512, 512]); ROIs:[torch.Size([300, 4])]; targets:torch.Size([1, 20])\n",
      "Output shape: (torch.Size([1, 300, 20]), tensor(0, device='cuda:0'))\n",
      "Compute loss:\n",
      "0.0033333334140479565\n",
      "0.05000000074505806\n",
      "Evaluating Model.\n",
      "Epoch: [0][0/4008]\tLoss 1733.2710\t\n",
      "Input shapes: Image torch.Size([1, 3, 512, 512]); ROIs:[torch.Size([300, 4])]; targets:torch.Size([1, 20])\n",
      "Output shape: (torch.Size([1, 300, 20]), tensor(0, device='cuda:0'))\n",
      "Compute loss:\n",
      "0.0033333334140479565\n",
      "0.10000000149011612\n",
      "Epoch: [0][10/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][20/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][30/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][40/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][50/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][60/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][70/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][80/4008]\tLoss 1700.0000\t\n",
      "Epoch: [0][90/4008]\tLoss 1700.0000\t\n",
      "Epoch: [0][100/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][110/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][120/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][130/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][140/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][150/4008]\tLoss 1700.0000\t\n",
      "Epoch: [0][160/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][170/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][180/4008]\tLoss 1700.0000\t\n",
      "Epoch: [0][190/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][200/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][210/4008]\tLoss 1400.0000\t\n",
      "Epoch: [0][220/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][230/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][240/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][250/4008]\tLoss 1700.0000\t\n",
      "Epoch: [0][260/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][270/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][280/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][290/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][300/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][310/4008]\tLoss 1700.0000\t\n",
      "Epoch: [0][320/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][330/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][340/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][350/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][360/4008]\tLoss 1700.0000\t\n",
      "Epoch: [0][370/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][380/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][390/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][400/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][410/4008]\tLoss 1700.0000\t\n",
      "Epoch: [0][420/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][430/4008]\tLoss 1700.0000\t\n",
      "Epoch: [0][440/4008]\tLoss 1700.0000\t\n",
      "Epoch: [0][450/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][460/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][470/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][480/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][490/4008]\tLoss 1700.0000\t\n",
      "Epoch: [0][500/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][510/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][520/4008]\tLoss 1600.0000\t\n",
      "Epoch: [0][530/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][540/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][550/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][560/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][570/4008]\tLoss 1700.0000\t\n",
      "Epoch: [0][580/4008]\tLoss 1700.0000\t\n",
      "Epoch: [0][590/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][600/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][610/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][620/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][630/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][640/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][650/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][660/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][670/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][680/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][690/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][700/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][710/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][720/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][730/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][740/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][750/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][760/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][770/4008]\tLoss 1700.0000\t\n",
      "Epoch: [0][780/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][790/4008]\tLoss 1800.0000\t\n",
      "Roi length rejected: 290\n",
      "Epoch: [0][800/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][810/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][820/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][830/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][840/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][850/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][860/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][870/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][880/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][890/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][900/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][910/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][920/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][930/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][940/4008]\tLoss 1800.0000\t\n",
      "Roi length rejected: 266\n",
      "Epoch: [0][960/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][970/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][980/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][990/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][1000/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1010/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1020/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1030/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][1040/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1050/4008]\tLoss 1700.0000\t\n",
      "Epoch: [0][1060/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1070/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][1080/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1090/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][1100/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1110/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][1120/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][1130/4008]\tLoss 1600.0000\t\n",
      "Epoch: [0][1140/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][1150/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1160/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1170/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1180/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1190/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][1200/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][1210/4008]\tLoss 1700.0000\t\n",
      "Epoch: [0][1220/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1230/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1240/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1250/4008]\tLoss 1500.0000\t\n",
      "Epoch: [0][1260/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1270/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][1280/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1290/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1300/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1310/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1320/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1330/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][1340/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1350/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1360/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1370/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1380/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1390/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1400/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][1410/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1420/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1430/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1440/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][1450/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1460/4008]\tLoss 1700.0000\t\n",
      "Epoch: [0][1470/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1480/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][1490/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][1500/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1510/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][1520/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1530/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1540/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1550/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][1560/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][1570/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1580/4008]\tLoss 1700.0000\t\n",
      "Epoch: [0][1590/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1600/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1610/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1620/4008]\tLoss 1700.0000\t\n",
      "Epoch: [0][1630/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][1640/4008]\tLoss 1700.0000\t\n",
      "Epoch: [0][1650/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1660/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1670/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1680/4008]\tLoss 1700.0000\t\n",
      "Epoch: [0][1690/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1700/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1710/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1720/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][1730/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1740/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][1750/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][1760/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1770/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1780/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1790/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1800/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][1810/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][1820/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][1830/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1840/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1850/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][1860/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][1870/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][1880/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][1890/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1900/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1910/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1920/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1930/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1940/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1950/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][1960/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1970/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][1980/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][1990/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][2000/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2010/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2020/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][2030/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2040/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][2050/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2060/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][2070/4008]\tLoss 1700.0000\t\n",
      "Epoch: [0][2080/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2090/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2100/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2110/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][2120/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2130/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][2140/4008]\tLoss 1700.0000\t\n",
      "Epoch: [0][2150/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2160/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2170/4008]\tLoss 1600.0000\t\n",
      "Epoch: [0][2180/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][2190/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][2200/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2210/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2220/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2230/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2240/4008]\tLoss 1700.0000\t\n",
      "Epoch: [0][2250/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2260/4008]\tLoss 1800.0000\t\n",
      "Roi length rejected: 49\n",
      "Epoch: [0][2270/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2280/4008]\tLoss 1700.0000\t\n",
      "Epoch: [0][2290/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2300/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2310/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2320/4008]\tLoss 1700.0000\t\n",
      "Epoch: [0][2330/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][2340/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][2350/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2360/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][2370/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][2380/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2390/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][2400/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2410/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2420/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][2430/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2440/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][2450/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2460/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][2470/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2480/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][2490/4008]\tLoss 1700.0000\t\n",
      "Epoch: [0][2500/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][2510/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2520/4008]\tLoss 1700.0000\t\n",
      "Roi length rejected: 214\n",
      "Epoch: [0][2530/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2540/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2550/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][2560/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2570/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2580/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2590/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2600/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2610/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2620/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][2630/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2640/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2650/4008]\tLoss 1600.0000\t\n",
      "Epoch: [0][2660/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][2670/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2680/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2690/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2700/4008]\tLoss 1700.0000\t\n",
      "Epoch: [0][2710/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2720/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][2730/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][2740/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2750/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2760/4008]\tLoss 1700.0000\t\n",
      "Epoch: [0][2770/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2780/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2790/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2800/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2810/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2820/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][2830/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2840/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2850/4008]\tLoss 1900.0000\t\n",
      "Roi length rejected: 157\n",
      "Epoch: [0][2870/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2880/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2890/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2900/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2910/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2920/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2930/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2940/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][2950/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][2960/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2970/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2980/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][2990/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3000/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3010/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][3020/4008]\tLoss 1700.0000\t\n",
      "Epoch: [0][3030/4008]\tLoss 1700.0000\t\n",
      "Epoch: [0][3040/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3050/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3060/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3070/4008]\tLoss 1700.0000\t\n",
      "Epoch: [0][3080/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3090/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3100/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][3110/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3120/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3130/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][3140/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3150/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][3160/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][3170/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3180/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3190/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3200/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3210/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3220/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][3230/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][3240/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][3250/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3260/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3270/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3280/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][3290/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3300/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][3310/4008]\tLoss 1700.0000\t\n",
      "Epoch: [0][3320/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3330/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][3340/4008]\tLoss 1700.0000\t\n",
      "Epoch: [0][3350/4008]\tLoss 1700.0000\t\n",
      "Epoch: [0][3360/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3370/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][3380/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3390/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3400/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3410/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3420/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3430/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][3440/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3450/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3460/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][3470/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3480/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3490/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3500/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3510/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3520/4008]\tLoss 1700.0000\t\n",
      "Epoch: [0][3530/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][3540/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][3550/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3560/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3570/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3580/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][3590/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3600/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][3610/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3620/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][3630/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3640/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][3650/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][3660/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3670/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3680/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3690/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3700/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3710/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][3720/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][3730/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3740/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3750/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3760/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3770/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3780/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3790/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][3800/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3810/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][3820/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][3830/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3840/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3850/4008]\tLoss 1700.0000\t\n",
      "Epoch: [0][3860/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3870/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3880/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3890/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3900/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][3910/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][3920/4008]\tLoss 1700.0000\t\n",
      "Epoch: [0][3930/4008]\tLoss 1700.0000\t\n",
      "Epoch: [0][3940/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][3950/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][3960/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][3970/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][3980/4008]\tLoss 1800.0000\t\n",
      "Epoch: [0][3990/4008]\tLoss 1900.0000\t\n",
      "Epoch: [0][4000/4008]\tLoss 1900.0000\t\n",
      "Input shapes: Image torch.Size([1, 3, 512, 512]); ROIs:[torch.Size([300, 4])]; targets:torch.Size([1, 20])\n",
      "Output shape: (torch.Size([1, 300, 20]), tensor(0, device='cuda:0'))\n",
      "Compute loss:\n",
      "0.0033333334140479565\n",
      "0.05000000074505806\n",
      "Evaluating Model.\n",
      "Epoch: [1][0/4008]\tLoss 1900.0000\t\n",
      "Input shapes: Image torch.Size([1, 3, 512, 512]); ROIs:[torch.Size([300, 4])]; targets:torch.Size([1, 20])\n",
      "Output shape: (torch.Size([1, 300, 20]), tensor(0, device='cuda:0'))\n",
      "Compute loss:\n",
      "0.0033333334140479565\n",
      "0.05000000074505806\n",
      "Epoch: [1][10/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][20/4008]\tLoss 1600.0000\t\n",
      "Epoch: [1][30/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][40/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][50/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][60/4008]\tLoss 1700.0000\t\n",
      "Epoch: [1][70/4008]\tLoss 1700.0000\t\n",
      "Epoch: [1][80/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][90/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][100/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][110/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][120/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][130/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][140/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][150/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][160/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][170/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][180/4008]\tLoss 1700.0000\t\n",
      "Epoch: [1][190/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][200/4008]\tLoss 1600.0000\t\n",
      "Epoch: [1][210/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][220/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][230/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][240/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][250/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][260/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][270/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][280/4008]\tLoss 1700.0000\t\n",
      "Epoch: [1][290/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][300/4008]\tLoss 1600.0000\t\n",
      "Epoch: [1][310/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][320/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][330/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][340/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][350/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][360/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][370/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][380/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][390/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][400/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][410/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][420/4008]\tLoss 1700.0000\t\n",
      "Epoch: [1][430/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][440/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][450/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][460/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][470/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][480/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][490/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][500/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][510/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][520/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][530/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][540/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][550/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][560/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][570/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][580/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][590/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][600/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][610/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][620/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][630/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][640/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][650/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][660/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][670/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][680/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][690/4008]\tLoss 1700.0000\t\n",
      "Epoch: [1][700/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][710/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][720/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][730/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][740/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][750/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][760/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][770/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][780/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][790/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][800/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][810/4008]\tLoss 1700.0000\t\n",
      "Epoch: [1][820/4008]\tLoss 1600.0000\t\n",
      "Epoch: [1][830/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][840/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][850/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][860/4008]\tLoss 1700.0000\t\n",
      "Epoch: [1][870/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][880/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][890/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][900/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][910/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][920/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][930/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][940/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][950/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][960/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][970/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][980/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][990/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1000/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1010/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1020/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1030/4008]\tLoss 1600.0000\t\n",
      "Epoch: [1][1040/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1050/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][1060/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][1070/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1080/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1090/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][1100/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][1110/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1120/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1130/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1140/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][1150/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][1160/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][1170/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1180/4008]\tLoss 1600.0000\t\n",
      "Epoch: [1][1190/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1200/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1210/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1220/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1230/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1240/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1250/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1260/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1270/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1280/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][1290/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1300/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][1310/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1320/4008]\tLoss 1700.0000\t\n",
      "Epoch: [1][1330/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][1340/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][1350/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1360/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1370/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1380/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1390/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][1400/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][1410/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1420/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1430/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1440/4008]\tLoss 1600.0000\t\n",
      "Epoch: [1][1450/4008]\tLoss 1700.0000\t\n",
      "Epoch: [1][1460/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][1470/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][1480/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1490/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1500/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][1510/4008]\tLoss 1700.0000\t\n",
      "Epoch: [1][1520/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][1530/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1540/4008]\tLoss 1700.0000\t\n",
      "Roi length rejected: 49\n",
      "Epoch: [1][1550/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1560/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1570/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1580/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1590/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1600/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1610/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][1620/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1630/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1640/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][1650/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1660/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1670/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][1680/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1690/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1700/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1710/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1720/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1730/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][1740/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1750/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][1760/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][1770/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1780/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1790/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1800/4008]\tLoss 1700.0000\t\n",
      "Epoch: [1][1810/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][1820/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1830/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][1840/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][1850/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1860/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][1870/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1880/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][1890/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1900/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1910/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1920/4008]\tLoss 1700.0000\t\n",
      "Epoch: [1][1930/4008]\tLoss 1700.0000\t\n",
      "Epoch: [1][1940/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][1950/4008]\tLoss 1700.0000\t\n",
      "Epoch: [1][1960/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][1970/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][1980/4008]\tLoss 1700.0000\t\n",
      "Epoch: [1][1990/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2000/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2010/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2020/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][2030/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2040/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2050/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2060/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][2070/4008]\tLoss 1700.0000\t\n",
      "Epoch: [1][2080/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][2090/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2100/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2110/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2120/4008]\tLoss 1700.0000\t\n",
      "Epoch: [1][2130/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][2140/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][2150/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2160/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2170/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2180/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2190/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][2200/4008]\tLoss 1700.0000\t\n",
      "Epoch: [1][2210/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2220/4008]\tLoss 1700.0000\t\n",
      "Epoch: [1][2230/4008]\tLoss 1700.0000\t\n",
      "Roi length rejected: 214\n",
      "Epoch: [1][2240/4008]\tLoss 1900.0000\t\n",
      "Roi length rejected: 266\n",
      "Epoch: [1][2260/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2270/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2280/4008]\tLoss 1700.0000\t\n",
      "Epoch: [1][2290/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2300/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2310/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2320/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2330/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2340/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2350/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][2360/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][2370/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2380/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2390/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][2400/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][2410/4008]\tLoss 1600.0000\t\n",
      "Epoch: [1][2420/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][2430/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2440/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2450/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][2460/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][2470/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][2480/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2490/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2500/4008]\tLoss 1700.0000\t\n",
      "Epoch: [1][2510/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2520/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2530/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2540/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2550/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2560/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2570/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2580/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2590/4008]\tLoss 1700.0000\t\n",
      "Epoch: [1][2600/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][2610/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2620/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][2630/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2640/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2650/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2660/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][2670/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][2680/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2690/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2700/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][2710/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2720/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2730/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][2740/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2750/4008]\tLoss 1700.0000\t\n",
      "Epoch: [1][2760/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2770/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2780/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2790/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2800/4008]\tLoss 1600.0000\t\n",
      "Epoch: [1][2810/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2820/4008]\tLoss 1700.0000\t\n",
      "Epoch: [1][2830/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][2840/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2850/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][2860/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2870/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2880/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][2890/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][2900/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2910/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2920/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2930/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2940/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2950/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][2960/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][2970/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][2980/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][2990/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3000/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3010/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][3020/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][3030/4008]\tLoss 1700.0000\t\n",
      "Epoch: [1][3040/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][3050/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][3060/4008]\tLoss 1600.0000\t\n",
      "Epoch: [1][3070/4008]\tLoss 1400.0000\t\n",
      "Epoch: [1][3080/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][3090/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3100/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][3110/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3120/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3130/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][3140/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3150/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3160/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3170/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3180/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3190/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3200/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3210/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][3220/4008]\tLoss 1900.0000\t\n",
      "Roi length rejected: 157\n",
      "Epoch: [1][3230/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3240/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3250/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3260/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][3270/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3280/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3290/4008]\tLoss 1700.0000\t\n",
      "Epoch: [1][3300/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][3310/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3320/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][3330/4008]\tLoss 1500.0000\t\n",
      "Epoch: [1][3340/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][3350/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][3360/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][3370/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][3380/4008]\tLoss 1700.0000\t\n",
      "Epoch: [1][3390/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3400/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3410/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3420/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][3430/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3440/4008]\tLoss 1700.0000\t\n",
      "Epoch: [1][3450/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3460/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3470/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][3480/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3490/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][3500/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3510/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][3520/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3530/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][3540/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][3550/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3560/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][3570/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3580/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3590/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3600/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][3610/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][3620/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][3630/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3640/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3650/4008]\tLoss 1700.0000\t\n",
      "Epoch: [1][3660/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][3670/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3680/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3690/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3700/4008]\tLoss 1600.0000\t\n",
      "Epoch: [1][3710/4008]\tLoss 1900.0000\t\n",
      "Roi length rejected: 290\n",
      "Epoch: [1][3730/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3740/4008]\tLoss 1600.0000\t\n",
      "Epoch: [1][3750/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3760/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3770/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3780/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][3790/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][3800/4008]\tLoss 1700.0000\t\n",
      "Epoch: [1][3810/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][3820/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3830/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][3840/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3850/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3860/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3870/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][3880/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3890/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][3900/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][3910/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][3920/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][3930/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3940/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][3950/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3960/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][3970/4008]\tLoss 1900.0000\t\n",
      "Epoch: [1][3980/4008]\tLoss 1800.0000\t\n",
      "Epoch: [1][3990/4008]\tLoss 1700.0000\t\n",
      "Epoch: [1][4000/4008]\tLoss 1900.0000\t\n",
      "Input shapes: Image torch.Size([1, 3, 512, 512]); ROIs:[torch.Size([300, 4])]; targets:torch.Size([1, 20])\n",
      "Output shape: (torch.Size([1, 300, 20]), tensor(0, device='cuda:0'))\n",
      "Compute loss:\n",
      "0.0033333334140479565\n",
      "0.05000000074505806\n",
      "Evaluating Model.\n",
      "Epoch: [2][0/4008]\tLoss 1900.0000\t\n",
      "Input shapes: Image torch.Size([1, 3, 512, 512]); ROIs:[torch.Size([300, 4])]; targets:torch.Size([1, 20])\n",
      "Output shape: (torch.Size([1, 300, 20]), tensor(0, device='cuda:0'))\n",
      "Compute loss:\n",
      "0.0033333334140479565\n",
      "0.05000000074505806\n",
      "Epoch: [2][10/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][20/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][30/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][40/4008]\tLoss 1700.0000\t\n",
      "Epoch: [2][50/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][60/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][70/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][80/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][90/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][100/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][110/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][120/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][130/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][140/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][150/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][160/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][170/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][180/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][190/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][200/4008]\tLoss 1600.0000\t\n",
      "Epoch: [2][210/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][220/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][230/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][240/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][250/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][260/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][270/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][280/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][290/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][300/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][310/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][320/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][330/4008]\tLoss 1600.0000\t\n",
      "Epoch: [2][340/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][350/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][360/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][370/4008]\tLoss 1700.0000\t\n",
      "Epoch: [2][380/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][390/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][400/4008]\tLoss 1700.0000\t\n",
      "Epoch: [2][410/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][420/4008]\tLoss 1700.0000\t\n",
      "Epoch: [2][430/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][440/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][450/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][460/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][470/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][480/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][490/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][500/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][510/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][520/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][530/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][540/4008]\tLoss 1700.0000\t\n",
      "Epoch: [2][550/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][560/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][570/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][580/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][590/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][600/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][610/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][620/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][630/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][640/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][650/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][660/4008]\tLoss 1700.0000\t\n",
      "Epoch: [2][670/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][680/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][690/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][700/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][710/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][720/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][730/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][740/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][750/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][760/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][770/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][780/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][790/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][800/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][810/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][820/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][830/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][840/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][850/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][860/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][870/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][880/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][890/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][900/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][910/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][920/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][930/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][940/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][950/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][960/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][970/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][980/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][990/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1000/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1010/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][1020/4008]\tLoss 1700.0000\t\n",
      "Epoch: [2][1030/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1040/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1050/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1060/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1070/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1080/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1090/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1100/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1110/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1120/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1130/4008]\tLoss 1700.0000\t\n",
      "Epoch: [2][1140/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1150/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1160/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1170/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][1180/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][1190/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1200/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1210/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][1220/4008]\tLoss 1600.0000\t\n",
      "Epoch: [2][1230/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1240/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][1250/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1260/4008]\tLoss 1700.0000\t\n",
      "Epoch: [2][1270/4008]\tLoss 1600.0000\t\n",
      "Epoch: [2][1280/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1290/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1300/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1310/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][1320/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1330/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1340/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][1350/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1360/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1370/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1380/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1390/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][1400/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1410/4008]\tLoss 1700.0000\t\n",
      "Epoch: [2][1420/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][1430/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1440/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][1450/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][1460/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][1470/4008]\tLoss 1700.0000\t\n",
      "Epoch: [2][1480/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1490/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1500/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1510/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][1520/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][1530/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][1540/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1550/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][1560/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1570/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1580/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1590/4008]\tLoss 1700.0000\t\n",
      "Epoch: [2][1600/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1610/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1620/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1630/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1640/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1650/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1660/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1670/4008]\tLoss 1600.0000\t\n",
      "Epoch: [2][1680/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][1690/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1700/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][1710/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1720/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][1730/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][1740/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][1750/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][1760/4008]\tLoss 1700.0000\t\n",
      "Epoch: [2][1770/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1780/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1790/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1800/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][1810/4008]\tLoss 1700.0000\t\n",
      "Epoch: [2][1820/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1830/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][1840/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][1850/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1860/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][1870/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1880/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1890/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1900/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1910/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][1920/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1930/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1940/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1950/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][1960/4008]\tLoss 1900.0000\t\n",
      "Roi length rejected: 157\n",
      "Epoch: [2][1970/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][1980/4008]\tLoss 1700.0000\t\n",
      "Epoch: [2][1990/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][2000/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2010/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][2020/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2030/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][2040/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][2050/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][2060/4008]\tLoss 1700.0000\t\n",
      "Epoch: [2][2070/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2080/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][2090/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][2100/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2110/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][2120/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2130/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2140/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2150/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2160/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][2170/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][2180/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2190/4008]\tLoss 1700.0000\t\n",
      "Epoch: [2][2200/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2210/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2220/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2230/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2240/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2250/4008]\tLoss 1700.0000\t\n",
      "Epoch: [2][2260/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2270/4008]\tLoss 1900.0000\t\n",
      "Roi length rejected: 290\n",
      "Epoch: [2][2280/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2290/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2300/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2310/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][2320/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][2330/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2340/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2350/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][2360/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2370/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2380/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][2390/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2400/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2410/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2420/4008]\tLoss 1600.0000\t\n",
      "Epoch: [2][2430/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2440/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][2450/4008]\tLoss 1700.0000\t\n",
      "Epoch: [2][2460/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2470/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2480/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][2490/4008]\tLoss 1700.0000\t\n",
      "Epoch: [2][2500/4008]\tLoss 1700.0000\t\n",
      "Epoch: [2][2510/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2520/4008]\tLoss 1600.0000\t\n",
      "Epoch: [2][2530/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2540/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][2550/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][2560/4008]\tLoss 1700.0000\t\n",
      "Epoch: [2][2570/4008]\tLoss 1500.0000\t\n",
      "Epoch: [2][2580/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][2590/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2600/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2610/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][2620/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][2630/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2640/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2650/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][2660/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][2670/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2680/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][2690/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][2700/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][2710/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2720/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2730/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2740/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2750/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2760/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2770/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2780/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2790/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2800/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][2810/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2820/4008]\tLoss 1700.0000\t\n",
      "Epoch: [2][2830/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2840/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][2850/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][2860/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2870/4008]\tLoss 1700.0000\t\n",
      "Epoch: [2][2880/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2890/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][2900/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2910/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2920/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2930/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2940/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2950/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][2960/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][2970/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][2980/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][2990/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][3000/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][3010/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3020/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3030/4008]\tLoss 1700.0000\t\n",
      "Epoch: [2][3040/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3050/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3060/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][3070/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][3080/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3090/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3100/4008]\tLoss 1700.0000\t\n",
      "Epoch: [2][3110/4008]\tLoss 1600.0000\t\n",
      "Epoch: [2][3120/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3130/4008]\tLoss 1600.0000\t\n",
      "Epoch: [2][3140/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][3150/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][3160/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3170/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][3180/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][3190/4008]\tLoss 1700.0000\t\n",
      "Epoch: [2][3200/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3210/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3220/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3230/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][3240/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3250/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3260/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3270/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3280/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3290/4008]\tLoss 1700.0000\t\n",
      "Epoch: [2][3300/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3310/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3320/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][3330/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3340/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3350/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3360/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3370/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3380/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3390/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][3400/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3410/4008]\tLoss 1700.0000\t\n",
      "Epoch: [2][3420/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][3430/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3440/4008]\tLoss 1700.0000\t\n",
      "Epoch: [2][3450/4008]\tLoss 1800.0000\t\n",
      "Roi length rejected: 49\n",
      "Epoch: [2][3460/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][3470/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3480/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][3490/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3500/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3510/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3520/4008]\tLoss 1700.0000\t\n",
      "Epoch: [2][3530/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3540/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3550/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3560/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3570/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3580/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3590/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][3600/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3610/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][3620/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3630/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3640/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3650/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][3660/4008]\tLoss 1700.0000\t\n",
      "Epoch: [2][3670/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][3680/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3690/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3700/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][3710/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3720/4008]\tLoss 1700.0000\t\n",
      "Epoch: [2][3730/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3740/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][3750/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3760/4008]\tLoss 1900.0000\t\n",
      "Roi length rejected: 214\n",
      "Epoch: [2][3770/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][3780/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3790/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3800/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3810/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3820/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3830/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3840/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3850/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3860/4008]\tLoss 1700.0000\t\n",
      "Epoch: [2][3870/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][3880/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3890/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][3900/4008]\tLoss 1700.0000\t\n",
      "Roi length rejected: 266\n",
      "Epoch: [2][3910/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3920/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3930/4008]\tLoss 1700.0000\t\n",
      "Epoch: [2][3940/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3950/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3960/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3970/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3980/4008]\tLoss 1900.0000\t\n",
      "Epoch: [2][3990/4008]\tLoss 1800.0000\t\n",
      "Epoch: [2][4000/4008]\tLoss 1900.0000\t\n",
      "Input shapes: Image torch.Size([1, 3, 512, 512]); ROIs:[torch.Size([300, 4])]; targets:torch.Size([1, 20])\n",
      "Output shape: (torch.Size([1, 300, 20]), tensor(0, device='cuda:0'))\n",
      "Compute loss:\n",
      "0.0033333334140479565\n",
      "0.05000000074505806\n",
      "Evaluating Model.\n",
      "Epoch: [3][0/4008]\tLoss 1900.0000\t\n",
      "Input shapes: Image torch.Size([1, 3, 512, 512]); ROIs:[torch.Size([300, 4])]; targets:torch.Size([1, 20])\n",
      "Output shape: (torch.Size([1, 300, 20]), tensor(0, device='cuda:0'))\n",
      "Compute loss:\n",
      "0.0033333334140479565\n",
      "0.05000000074505806\n",
      "Epoch: [3][10/4008]\tLoss 1800.0000\t\n",
      "Epoch: [3][20/4008]\tLoss 1900.0000\t\n",
      "Epoch: [3][30/4008]\tLoss 1800.0000\t\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26325/2494279301.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Start train.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_26325/3620555523.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, optimizer, args)\u001b[0m\n\u001b[1;32m    181\u001b[0m                         \"predictions\": {\n\u001b[1;32m    182\u001b[0m                             \u001b[0;34m\"box_data\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_box_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gt_classes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gt_boxes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m                             \u001b[0;34m\"class_labels\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mclass_id_to_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m                         },\n\u001b[1;32m    185\u001b[0m                     })\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/wandb/sdk/data_types/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_or_path, mode, caption, grouping, classes, boxes, masks)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_from_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_initialization_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrouping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaption\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/wandb/sdk/data_types/image.py\u001b[0m in \u001b[0;36m_initialize_from_data\u001b[0;34m(self, data, mode)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mtmp_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMEDIA_TMP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"png\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransparency\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_tmp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2299\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2300\u001b[0;31m             \u001b[0msave_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2301\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2302\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mopen_fp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/PIL/PngImagePlugin.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, filename, chunk, save_all)\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0m_write_multiple_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m         \u001b[0mImageFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_idat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"zip\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    516\u001b[0m                     \u001b[0;31m# compress to Python file-compatible object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m                     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m                         \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m                         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "print(\"Start train.\")\n",
    "train_model(net, train_loader, val_loader, optimizer, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289d0d66-6205-4489-95d2-3c4a433b4bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
