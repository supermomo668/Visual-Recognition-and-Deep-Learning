{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b96597e-2e64-4f33-b4d8-15a1c900766b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torch.nn.parameter import Parameter\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pickle as pkl\n",
    "\n",
    "# imports\n",
    "from wsddn import WSDDN\n",
    "from voc_dataset import *\n",
    "import wandb\n",
    "from utils import nms, tensor_to_PIL\n",
    "from PIL import Image, ImageDraw\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "\n",
    "#\n",
    "from torchcam.methods import SmoothGradCAMpp\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68fad5dd-89ca-4b58-99e8-4969dfd0d440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__module__': '__main__', 'parsed_args': Namespace(disp_interval=10, epochs=5, lr=0.0001, lr_decay=0.1, lr_decay_steps=150000, momentum=0.9, use_wandb=False, val_interval=5000, weight_decay=0.0005), 'batch_size': 16, 'workers': 2, 'disp_interval': 10, 'val_interval': 5000, 'epochs': 5, 'lr': 0.0001, 'use_wandb': False, 'pretrained': True, 'momentum': 0.9, 'weight_decay': 0.0005, '__dict__': <attribute '__dict__' of 'args' objects>, '__weakref__': <attribute '__weakref__' of 'args' objects>, '__doc__': None}\n"
     ]
    }
   ],
   "source": [
    "# hyper-parameters\n",
    "# ------------\n",
    "parser = argparse.ArgumentParser(description='PyTorch ImageNet Training')\n",
    "parser.add_argument(\n",
    "    '--lr',\n",
    "    default=0.0001,\n",
    "    type=float,\n",
    "    help='Learning rate'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--lr-decay-steps',\n",
    "    default=150000,\n",
    "    type=int,\n",
    "    help='Interval at which the lr is decayed'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--lr-decay',\n",
    "    default=0.1,\n",
    "    type=float,\n",
    "    help='Decay rate of lr'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--momentum',\n",
    "    default=0.9,\n",
    "    type=float,\n",
    "    help='Momentum of optimizer'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--weight-decay',\n",
    "    default=0.0005,\n",
    "    type=float,\n",
    "    help='Weight decay'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--epochs',\n",
    "    default=5,\n",
    "    type=int,\n",
    "    help='Number of epochs'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--val-interval',\n",
    "    default=5000,\n",
    "    type=int,\n",
    "    help='Interval at which to perform validation'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--disp-interval',\n",
    "    default=10,\n",
    "    type=int,\n",
    "    help='Interval at which to perform visualization'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--use-wandb',\n",
    "    default=False,\n",
    "    type=bool,\n",
    "    help='Flag to enable visualization'\n",
    ")\n",
    "\n",
    "class args:\n",
    "    parsed_args = parser.parse_known_args()[0]\n",
    "    batch_size = 16\n",
    "    workers = 2\n",
    "    disp_interval = parsed_args.disp_interval\n",
    "    val_interval= parsed_args.val_interval\n",
    "    epochs = parsed_args.epochs\n",
    "    lr= parsed_args.lr\n",
    "    use_wandb = parsed_args.use_wandb\n",
    "    pretrained = True\n",
    "    momentum = parsed_args.momentum\n",
    "    weight_decay = parsed_args.weight_decay\n",
    "    #start_epoch = parsed_args.start_epoch\n",
    "print(args.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7df7a257-5ac3-4d2e-8443-0659f4912a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path:/home/mo/hw/hw1-object_localization/data/VOCdevkit/VOC2007\n"
     ]
    }
   ],
   "source": [
    "global args\n",
    "# TODO (Q2.2): Load datasets and create dataloaders\n",
    "dataset = VOCDataset('trainval', top_n=300, image_size=512, data_dir='./data/VOCdevkit/VOC2007/')\n",
    "n = len(dataset)\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [int(np.floor(n*0.8)), n-int(np.floor(n*0.8))])\n",
    "train_sampler = torch.utils.data.SubsetRandomSampler(range(len(train_dataset)))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=args.workers,\n",
    "    pin_memory=True,\n",
    "    sampler=train_sampler,\n",
    "    collate_fn=custom_collate_fn_VOC,\n",
    "    drop_last=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=args.workers,\n",
    "    pin_memory=True,\n",
    "    collate_fn=custom_collate_fn_VOC,\n",
    "    drop_last=True)\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "# Initialize wandb logger\n",
    "if args.use_wandb:\n",
    "    wandb.init(project=\"vlr-hw1\", reinit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e857e6a4-764f-44b3-9aa5-bc66711dacb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "rand_seed = 1024\n",
    "if rand_seed is not None:\n",
    "    np.random.seed(rand_seed)\n",
    "    torch.manual_seed(rand_seed)\n",
    "\n",
    "# Set output directory\n",
    "output_dir = \"./\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "\n",
    "def metric1(output, target):\n",
    "    # TODO (Q1.5): compute metric1\n",
    "    target = target.detach().numpy()\n",
    "    output = output.detach().numpy()\n",
    "    mean_ap = sklearn.metrics.average_precision_score(target, output, average='micro')\n",
    "    return mean_ap    #[0]\n",
    "\n",
    "def calculate_map(output, target):\n",
    "    thres=0.5\n",
    "    \"\"\"\n",
    "    Calculate the mAP for classification.\n",
    "    \"\"\"\n",
    "    # TODO (Q2.3): Calculate mAP on test set.\n",
    "    target = target.detach().numpy()\n",
    "    output = output.detach().numpy()\n",
    "    mean_ap = sklearn.metrics.average_precision_score(target, output, average=None)\n",
    "    # Feel free to write necessary function parameters.\n",
    "    return np.nan_to_num(mean_ap, 0)\n",
    "\n",
    "def test_model(model, val_loader=None, thresh=0.05):\n",
    "    \"\"\"\n",
    "    Tests the networks and visualizes the detections\n",
    "    :param thresh: Confidence threshold\n",
    "    \"\"\"\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader):\n",
    "\n",
    "            # one batch = data for one image\n",
    "            image = data['image']\n",
    "            target = data['label']\n",
    "            wgt = data['wgt']\n",
    "            rois = data['rois']\n",
    "            gt_boxes = data['gt_boxes']\n",
    "            gt_class_list = data['gt_classes']\n",
    "            # TODO (Q2.3): perform forward pass, compute cls_probs\n",
    "            cls_prob = model(image, rois, target)\n",
    "            \n",
    "            loss = model.loss\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # TODO (Q2.3): Iterate over each class (follow comments)\n",
    "            for class_num in range(20):\n",
    "                # get valid rois and cls_scores based on thresh\n",
    "                class_idx = np.where(target==class_num)\n",
    "                rois_ = rois[class_idx]\n",
    "                \n",
    "                # use NMS to get boxes and scores\n",
    "                pass\n",
    "\n",
    "            # TODO (Q2.3): visualize bounding box predictions when required\n",
    "            calculate_map(cls_prob.cpu(), target.cpu())\n",
    "\n",
    "\n",
    "def train_model(model, train_loader=None, val_loader=None, optimizer=None, args=None):\n",
    "    \"\"\"\n",
    "    Trains the network, runs evaluation and visualizes the detections\n",
    "    \"\"\"\n",
    "    # Initialize training variables\n",
    "    train_loss = 0\n",
    "    step_cnt = 0\n",
    "    for epoch in range(args.epochs):\n",
    "        for i, data in enumerate(train_loader):\n",
    "            debug=True if (epoch==0 and i==0) else False\n",
    "            # TODO (Q2.2): get one batch and perform forward pass\n",
    "            # one batch = data for one image\n",
    "            image = data['image']\n",
    "            target = data['label']\n",
    "            wgt = data['wgt']\n",
    "            rois = data['rois']\n",
    "            gt_boxes = data['gt_boxes']\n",
    "            gt_class_list = data['gt_classes']\n",
    "\n",
    "            # TODO (Q2.2): perform forward pass\n",
    "            # take care that proposal values should be in pixels\n",
    "            # Convert inputs to cuda if training on GPU\n",
    "            if debug: print(f\"Input shapes: Image {image.size()}; ROIs:{len(rois), type(rois[0])}; targets:{target.size()}\")\n",
    "            cls_prob = model(image, rois, target)\n",
    "            if debug: print(f\"Output shape: {cls_prob.size()}\")\n",
    "            # backward pass and update\n",
    "            loss = model.loss\n",
    "            train_loss += loss.item()\n",
    "            step_cnt += 1\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # measure metrics and record loss\n",
    "            m1 = metric1(cls_prob.cpu(), target.cpu())\n",
    "            \n",
    "            # TODO (Q2.2): evaluate the model every N iterations (N defined in handout)\n",
    "            # Add wandb logging wherever necessary\n",
    "            if i % args.val_interval == 0 and iter != 0:\n",
    "                model.eval()\n",
    "                ap = test_model(model, val_loader)\n",
    "                print(\"AP \", ap)\n",
    "                model.train()\n",
    "            \n",
    "            # TODO (Q2.4): Perform all visualizations here\n",
    "            # The intervals for different things are defined in the handout\n",
    "            if i % args.disp_interval==0:\n",
    "                print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Metric1 {avg_m1.val:.3f} ({avg_m1.avg:.3f})\\t'\n",
    "                  'Metric2 {avg_m2.val:.3f} ({avg_m2.avg:.3f})'.format(\n",
    "                      epoch,\n",
    "                      i,\n",
    "                      len(train_loader),\n",
    "                      batch_time=batch_time,\n",
    "                      data_time=data_time,\n",
    "                      loss=losses,\n",
    "                      avg_m1=avg_m1,\n",
    "                      avg_m2=avg_m2)\n",
    "                )\n",
    "                #logger.model_param_histo_summary(model=net, step=step)\n",
    "                pass\n",
    "                #\n",
    "            if (epoch==0 or epoch==1 ) and i==0:\n",
    "                table = wandb.Table(columns=[\"image\",\"predicted class score\"])\n",
    "                for n, (im, out_heatmap) in enumerate(zip(input_im, vis_heatmap)):\n",
    "                    input_img = wandb.Image(im, boxes={\n",
    "                        \"predictions\": {\n",
    "                            \"box_data\": get_box_data(data['gt_classes'][n], data['gt_boxes'][n]),\n",
    "                            \"class_labels\": class_id_to_label,       \n",
    "                        },\n",
    "                    })\n",
    "                    # Log selective masks\n",
    "                    table.add_data(input_img, cls_prob)\n",
    "                    if n==1: \n",
    "                        wandb.log({\"Visuals\": table})\n",
    "                        break\n",
    "            wandb.log(\n",
    "                {'train/loss':loss, 'train/metric1': m1} #,  'train/metric2': m2,}\n",
    "            )\n",
    "    # TODO (Q2.4): Plot class-wise APs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edad5f1-5e1b-4286-9b46-342db690f940",
   "metadata": {},
   "source": [
    "<b> Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e92bab62-2caf-4deb-b568-48efab2fe414",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes:['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WSDDN(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=0, dilation=(1, 1), ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=0, dilation=(1, 1), ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU()\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (roi_pool): RoIPool(output_size=(6, 6), spatial_scale=0.0625)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "  )\n",
       "  (score_out): Sequential(\n",
       "    (0): Linear(in_features=4096, out_features=20, bias=True)\n",
       "  )\n",
       "  (bbox_out): Sequential(\n",
       "    (0): Linear(in_features=4096, out_features=20, bias=True)\n",
       "  )\n",
       "  (criterion): BCELoss()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create network and initialize\n",
    "net = WSDDN(classes=dataset.CLASS_NAMES)\n",
    "\n",
    "if os.path.exists('pretrained_alexnet.pkl'):\n",
    "    pret_net = pkl.load(open('pretrained_alexnet.pkl', 'rb'))\n",
    "else:\n",
    "    pret_net = model_zoo.load_url(\n",
    "        'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth')\n",
    "    pkl.dump(pret_net,\n",
    "    open('pretrained_alexnet.pkl', 'wb'), pkl.HIGHEST_PROTOCOL)\n",
    "own_state = net.state_dict()\n",
    "\n",
    "for name, param in pret_net.items():\n",
    "    if name not in own_state:\n",
    "        continue\n",
    "    if isinstance(param, Parameter):\n",
    "        param = param.data\n",
    "    try:\n",
    "        own_state[name].copy_(param)\n",
    "    except:\n",
    "        print('Did not find {}'.format(name))\n",
    "        continue\n",
    "\n",
    "# Move model to GPU and set train mode\n",
    "net.load_state_dict(own_state)\n",
    "net.cuda()\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e71508e-6f2d-4501-a436-938f377ccfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (Q2.2): Freeze AlexNet layers since we are loading a pretrained model\n",
    "for param in net.features.parameters():\n",
    "    param.requires_grad = False\n",
    "# TODO (Q2.2): Create optimizer only for network parameters that are trainable\n",
    "params = list(net.parameters())\n",
    "optimizer = torch.optim.SGD(params, lr=args.lr, \n",
    "                            momentum=args.momentum, weight_decay=args.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0722c509-2521-4657-a135-ef4bfe82ba67",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shapes: Image torch.Size([16, 3, 512, 512]); ROIs:(16, <class 'torch.Tensor'>); targets:torch.Size([16, 20])\n",
      "Output shape: torch.Size([16, 20])\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'train_loss' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18372/3264545828.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_18372/679924209.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, optimizer, args)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0miter\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                 \u001b[0map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AP \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_18372/679924209.py\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(model, val_loader, thresh)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;31m# TODO (Q2.3): Iterate over each class (follow comments)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'train_loss' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "train_model(net, train_loader, val_loader, optimizer, args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
