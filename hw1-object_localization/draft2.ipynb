{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b96597e-2e64-4f33-b4d8-15a1c900766b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import warnings\n",
    "#warnings.filterwarnings('error')\n",
    "# with warnings.catch_warnings():\n",
    "#     warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "    \n",
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torch.nn.parameter import Parameter\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# imports\n",
    "from wsddn import WSDDN\n",
    "from voc_dataset import *\n",
    "import wandb\n",
    "from utils import nms, tensor_to_PIL\n",
    "from PIL import Image, ImageDraw\n",
    "import sklearn.metrics\n",
    "from utils import *\n",
    "#\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68fad5dd-89ca-4b58-99e8-4969dfd0d440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__module__': '__main__', 'parsed_args': Namespace(disp_interval=10, epochs=5, lr=0.0001, lr_decay=0.1, lr_decay_steps=150000, momentum=0.9, use_wandb=True, val_interval=5000, weight_decay=0.0005), 'batch_size': 2, 'workers': 2, 'disp_interval': 10, 'val_interval': 5000, 'epochs': 5, 'lr': 0.0001, 'use_wandb': True, 'pretrained': True, 'momentum': 0.9, 'weight_decay': 0.0005, '__dict__': <attribute '__dict__' of 'args' objects>, '__weakref__': <attribute '__weakref__' of 'args' objects>, '__doc__': None}\n"
     ]
    }
   ],
   "source": [
    "# hyper-parameters\n",
    "# ------------\n",
    "parser = argparse.ArgumentParser(description='PyTorch ImageNet Training')\n",
    "parser.add_argument(\n",
    "    '--lr',\n",
    "    default=0.0001,\n",
    "    type=float,\n",
    "    help='Learning rate'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--lr-decay-steps',\n",
    "    default=150000,\n",
    "    type=int,\n",
    "    help='Interval at which the lr is decayed'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--lr-decay',\n",
    "    default=0.1,\n",
    "    type=float,\n",
    "    help='Decay rate of lr'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--momentum',\n",
    "    default=0.9,\n",
    "    type=float,\n",
    "    help='Momentum of optimizer'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--weight-decay',\n",
    "    default=0.0005,\n",
    "    type=float,\n",
    "    help='Weight decay'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--epochs',\n",
    "    default=5,\n",
    "    type=int,\n",
    "    help='Number of epochs'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--val-interval',\n",
    "    default=5000,\n",
    "    type=int,\n",
    "    help='Interval at which to perform validation'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--disp-interval',\n",
    "    default=10,\n",
    "    type=int,\n",
    "    help='Interval at which to perform visualization'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--use-wandb',\n",
    "    default=True,\n",
    "    type=bool,\n",
    "    help='Flag to enable visualization'\n",
    ")\n",
    "\n",
    "class args:\n",
    "    parsed_args = parser.parse_known_args()[0]\n",
    "    batch_size = 2\n",
    "    workers = 2\n",
    "    disp_interval = parsed_args.disp_interval\n",
    "    val_interval= parsed_args.val_interval\n",
    "    epochs = parsed_args.epochs\n",
    "    lr= parsed_args.lr\n",
    "    use_wandb = parsed_args.use_wandb\n",
    "    pretrained = True\n",
    "    momentum = parsed_args.momentum\n",
    "    weight_decay = parsed_args.weight_decay\n",
    "    #start_epoch = parsed_args.start_epoch\n",
    "print(args.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7df7a257-5ac3-4d2e-8443-0659f4912a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path:/home/mo/hw/hw1-object_localization/data/VOCdevkit/VOC2007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m3m-m\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mo/hw/hw1-object_localization/wandb/run-20221006_192810-1f0qqcz7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/3m-m/vlr-hw1%28task2%29/runs/1f0qqcz7\" target=\"_blank\">dauntless-fog-6</a></strong> to <a href=\"https://wandb.ai/3m-m/vlr-hw1%28task2%29\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "global args\n",
    "# TODO (Q2.2): Load datasets and create dataloaders\n",
    "dataset = VOCDataset('trainval', top_n=300, image_size=512, data_dir='./data/VOCdevkit/VOC2007/')\n",
    "n = len(dataset)\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [int(np.floor(n*0.8)), n-int(np.floor(n*0.8))])\n",
    "train_sampler = torch.utils.data.SubsetRandomSampler(range(len(train_dataset)))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=args.workers,\n",
    "    pin_memory=True,\n",
    "    sampler=train_sampler,\n",
    "    collate_fn=custom_collate_fn_VOC,\n",
    "    drop_last=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=args.workers,\n",
    "    pin_memory=True,\n",
    "    collate_fn=custom_collate_fn_VOC,\n",
    "    drop_last=True)\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "# Initialize wandb logger\n",
    "if args.use_wandb:\n",
    "    wandb.init(project=\"vlr-hw1(task2)\", reinit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e857e6a4-764f-44b3-9aa5-bc66711dacb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "rand_seed = 1024\n",
    "if rand_seed is not None:\n",
    "    np.random.seed(rand_seed)\n",
    "    torch.manual_seed(rand_seed)\n",
    "\n",
    "# Set output directory\n",
    "output_dir = \"./\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "def metric1(output, target):\n",
    "    # TODO (Q1.5): compute metric1\n",
    "    target = target.detach().numpy().astype('int')\n",
    "    output = output.detach().numpy().astype('float')\n",
    "    # get features that aren't all zero\n",
    "    feat_considered = ~np.all(np.concatenate([target, output]), axis=0)\n",
    "    mean_ap = sklearn.metrics.average_precision_score(target[:,feat_considered], output[:,feat_considered], average='samples')\n",
    "    return mean_ap    #[0]\n",
    "\n",
    "def calculate_map(roi_bboxes, box_scores,  gt_classes, gt_bboxes, n_classes=20):\n",
    "    \"\"\"\n",
    "    Calculate the mAP for classification.\n",
    "    #        \n",
    "    \"\"\"\n",
    "    # TODO (Q2.3): Calculate mAP on test set.\n",
    "    # Using IOU to iterate each box for each class\n",
    "    # Compare each iteratively and take Maximum IOU\n",
    "    pred_boxes, gt_boxes = np.asarray(roi_bboxes), np.asarray(gt_bboxes)\n",
    "    per_class_iou = np.zeros(n_classes)   # ( 20)\n",
    "    filtered_bboxes = []\n",
    "    cls_labels = []\n",
    "    for class_num in range(20):   # (per class)\n",
    "        gt_class_idx = np.where(np.asarray(gt_classes)==class_num)[0]\n",
    "        pred_class_idx = np.where(np.argmax(np.asarray(roi_bboxes), axis=1)==class_num)[0]\n",
    "        if len(pred_class_idx)==0 or len(gt_class_idx)==0:\n",
    "            per_class_iou[class_num] = 0\n",
    "            continue\n",
    "        pred_class_bbox, gt_class_bbox = pred_boxes[pred_class_idx], gt_boxes[gt_class_idx]\n",
    "        #\n",
    "        bboxes, conf_scores = nms(pred_class_bbox, box_scores[pred_class_idx])\n",
    "        filtered_bboxes.append(bboxes)\n",
    "        cls_labels += [class_num]*len(bboxes)\n",
    "        # iterate each bbox to gt bbox\n",
    "        class_iou = []\n",
    "        for i, pred_box in enumerate(pred_class_bbox):\n",
    "            class_iou.append(np.max([iou(pred_box, gt_box) for gt_box in gt_class_bbox]))\n",
    "        per_class_iou[class_num] = np.array(class_iou).mean()\n",
    "    return per_class_iou, (filtered_bboxes, cls_labels)\n",
    "\n",
    "\n",
    "def test_model(model, val_loader=None, thresh=0.05):\n",
    "    \"\"\"\n",
    "    Tests the networks and visualizes the detections\n",
    "    :param thresh: Confidence threshold\n",
    "    \"\"\"\n",
    "    test_loss = 0\n",
    "    class_id_to_label = dict(enumerate(dataset.CLASS_NAMES))\n",
    "    class_ap_table = wandb.Table(columns=dataset.CLASS_NAMES)\n",
    "    vis_table = wandb.Table(columns=[\"image\", \"prediction\", \"mean class scores\"])\n",
    "    batch_class_ap = []\n",
    "    #\n",
    "    with torch.no_grad():\n",
    "        batch_ap_by_class = []\n",
    "        for i, data in enumerate(val_loader):\n",
    "            # one batch = data for one image\n",
    "            image = data['image']\n",
    "            target = data['label']\n",
    "            wgt = data['wgt']\n",
    "            rois = data['rois']\n",
    "            gt_boxes = data['gt_boxes']\n",
    "            gt_class = data['gt_classes']\n",
    "            if np.any([len(r)!= 300 for r in rois]):\n",
    "                print([len(r) for r in rois])\n",
    "                continue\n",
    "            img_info = dict.fromkeys(np.arange(args.batch_size), {'pred_boxes':[],'pred_cls':[]})\n",
    "            # TODO (Q2.3): perform forward pass, compute cls_probs\n",
    "            box_prob = model(image, rois, target)   # (N, 300, 20)\n",
    "            \n",
    "            loss = model.build_loss(box_prob, target)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # TODO (Q2.3): Iterate over each class (follow comments)\n",
    "            for n in range(args.batch_size):\n",
    "                # Get NMS bboxes\n",
    "                ap_by_class, (pred_boxes, labels) = calculate_map(rois[n], box_prob[n].detach().cpu(),  gt_class[n], gt_boxes[n])\n",
    "                batch_class_ap.append(ap_by_class)\n",
    "                pred_boxes.append(pred_boxes)\n",
    "            running_mean_ap = np.mean(np.stack(batch_class_ap), axis=0)\n",
    "            class_ap_table.add_data(*running_mean_ap)\n",
    "            # TODO (Q2.3): visualize bounding box predictions when required\n",
    "            if i%args.val_interval==0:\n",
    "                for n, im in enumerate(image):\n",
    "                    gtbbox_img = wandb.Image(im, boxes={\n",
    "                        \"predictions\": {\n",
    "                        \"box_data\": get_box_data(data['gt_classes'][n], data['gt_boxes'][n]),\n",
    "                        \"class_labels\": class_id_to_label,       \n",
    "                        },\n",
    "                    })\n",
    "                    predbbox_img = wandb.Image(im, boxes={\n",
    "                        \"predictions\": {\n",
    "                        \"box_data\": get_box_data(img_info[n]['pred_cls'], img_info[n]['pred_boxes']),\n",
    "                        \"class_labels\": class_id_to_label,       \n",
    "                        },\n",
    "                    })\n",
    "                    vis_table.add_data(wandb.Image(im), gtbbox_img, predbbox_img)    \n",
    "        wandb.log({\"Visuals\": vis_table})\n",
    "        wandb.log({\"AP by Class\": class_ap_table})\n",
    "    return np.nanmean(np.stack(batch_class_ap), axis=0)\n",
    "            \n",
    "\n",
    "\n",
    "def train_model(model, train_loader=None, val_loader=None, optimizer=None, args=None):\n",
    "    \"\"\"\n",
    "    Trains the network, runs evaluation and visualizes the detections\n",
    "    \"\"\"\n",
    "    # Initialize training variables\n",
    "    train_loss = 0\n",
    "    step_cnt = 0\n",
    "    class_id_to_label = dict(enumerate(dataset.CLASS_NAMES))\n",
    "    class_ap_table = wandb.Table(columns=dataset.CLASS_NAMES)\n",
    "    vis_table = wandb.Table(columns=[\"image\", \"class AP scores\"])\n",
    "    for epoch in range(args.epochs):\n",
    "        for i, data in enumerate(train_loader):\n",
    "            debug=True if (epoch==0 and i==0) else False\n",
    "            # TODO (Q2.2): get one batch and perform forward pass\n",
    "            # one batch = data for one image\n",
    "            image = data['image']\n",
    "            target = data['label']\n",
    "            wgt = data['wgt']\n",
    "            rois = data['rois']\n",
    "            gt_boxes = data['gt_boxes']\n",
    "            gt_class = data['gt_classes']\n",
    "            if np.any([len(r)!= 300 for r in rois]):\n",
    "                continue\n",
    "            print(np.any([len(r)!= 300 for r in rois]), [len(r) for r in rois])\n",
    "            # TODO (Q2.2): perform forward pass\n",
    "            # take care that proposal values should be in pixels\n",
    "            # Convert inputs to cuda if training on GPU\n",
    "            if debug: print(f\"Input shapes: Image {image.size()}; ROIs:{[len(r) for r in rois]}; targets:{target.size()}\")\n",
    "            box_prob = model(image, rois, target)   # (N, 300, 20)\n",
    "            if debug: print(f\"Output shape: {box_prob.size()}\")\n",
    "            # backward pass and update\n",
    "            loss = model.loss\n",
    "            train_loss += loss.item()\n",
    "            step_cnt += 1\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # measure metrics and record loss\n",
    "            #m1 = metric1(torch.sum(box_prob,dim=1).cpu(), target.cpu())\n",
    "            wandb.log(\n",
    "                {'train/loss':loss}, #'train/metric1': m1} #,  'train/metric2': m2,}\n",
    "            )\n",
    "            # TODO (Q2.2): evaluate the model every N iterations (N defined in handout)\n",
    "            # Add wandb logging wherever necessary\n",
    "            if i % args.val_interval == 0 and iter != 0:\n",
    "                print(\"Evaluating Model.\")\n",
    "                model.eval()\n",
    "                ap = test_model(model, val_loader)\n",
    "                model.train()\n",
    "            \n",
    "            # TODO (Q2.4): Perform all visualizations here\n",
    "            # The intervals for different things are defined in the handout\n",
    "            if i % args.disp_interval==0:\n",
    "                print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Loss {train_loss:.4f}\\t'.format(\n",
    "                      epoch,\n",
    "                      i,\n",
    "                      len(train_loader),\n",
    "                      train_loss=train_loss,\n",
    "                      #metric1=m1,\n",
    "                      # ap=ap,\n",
    "                  )\n",
    "                )\n",
    "                #logger.model_param_zhisto_summary(model=net, step=step)\n",
    "                #\n",
    "            if i%args.disp_interval:\n",
    "                for n, im in enumerate(image):\n",
    "                    input_img = wandb.Image(im, boxes={\n",
    "                        \"predictions\": {\n",
    "                            \"box_data\": get_box_data(data['gt_classes'][n], data['gt_boxes'][n]),\n",
    "                            \"class_labels\": class_id_to_label,       \n",
    "                        },\n",
    "                    })\n",
    "                    # predbbox_img = wandb.Image(im, boxes={\n",
    "                    #     \"predictions\": {\n",
    "                    #     \"box_data\": get_box_data(img_info[n]['pred_boxes'], img_info[n]['pred_boxes']),\n",
    "                    #     \"class_labels\": class_id_to_label,       \n",
    "                    #     },\n",
    "                    # })\n",
    "                    vis_table.add_data(input_img, ap)\n",
    "                wandb.log({\"train/Visuals\": vis_table})\n",
    "                # wandb.log({\"AP by Class\": class_ap_table})\n",
    "    \n",
    "    # TODO (Q2.4): Plot class-wise APs\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "b999879e-6ba9-4fbb-b896-1688d888ed56",
   "metadata": {
    "tags": []
   },
   "source": [
    "test_model(net, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edad5f1-5e1b-4286-9b46-342db690f940",
   "metadata": {},
   "source": [
    "<b> Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e92bab62-2caf-4deb-b568-48efab2fe414",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes:['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WSDDN(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=0, dilation=(1, 1), ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=0, dilation=(1, 1), ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU()\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (roi_pool): RoIPool(output_size=(6, 6), spatial_scale=0.0625)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "  )\n",
       "  (score_out): Sequential(\n",
       "    (0): Linear(in_features=4096, out_features=20, bias=True)\n",
       "  )\n",
       "  (bbox_out): Sequential(\n",
       "    (0): Linear(in_features=4096, out_features=20, bias=True)\n",
       "  )\n",
       "  (criterion): MultiLabelSoftMarginLoss()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create network and initialize\n",
    "net = WSDDN(classes=dataset.CLASS_NAMES)\n",
    "\n",
    "if os.path.exists('pretrained_alexnet.pkl'):\n",
    "    pret_net = pkl.load(open('pretrained_alexnet.pkl', 'rb'))\n",
    "else:\n",
    "    pret_net = model_zoo.load_url(\n",
    "        'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth')\n",
    "    pkl.dump(pret_net,\n",
    "    open('pretrained_alexnet.pkl', 'wb'), pkl.HIGHEST_PROTOCOL)\n",
    "own_state = net.state_dict()\n",
    "\n",
    "for name, param in pret_net.items():\n",
    "    if name not in own_state:\n",
    "        continue\n",
    "    if isinstance(param, Parameter):\n",
    "        param = param.data\n",
    "    try:\n",
    "        own_state[name].copy_(param)\n",
    "    except:\n",
    "        print('Did not find {}'.format(name))\n",
    "        continue\n",
    "\n",
    "# Move model to GPU and set train mode\n",
    "net.load_state_dict(own_state)\n",
    "net.cuda()\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e71508e-6f2d-4501-a436-938f377ccfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (Q2.2): Freeze AlexNet layers since we are loading a pretrained model\n",
    "for param in net.features.parameters():\n",
    "    param.requires_grad = False\n",
    "# TODO (Q2.2): Create optimizer only for network parameters that are trainable\n",
    "params = list(net.parameters())\n",
    "optimizer = torch.optim.SGD(params, lr=args.lr, \n",
    "                            momentum=args.momentum, weight_decay=args.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1330cd2-9e4a-4bc4-8c36-d1616c5ca6ec",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start train.\n",
      "False [300, 300]\n",
      "Input shapes: Image torch.Size([2, 3, 512, 512]); ROIs:[300, 300]; targets:torch.Size([2, 20])\n",
      "Output shape: torch.Size([2, 300, 20])\n",
      "Evaluating Model.\n",
      "[300, 266]\n",
      "Epoch: [0][0/2004]\tLoss 0.2038\t\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "Epoch: [0][10/2004]\tLoss 2.7904\t\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "Epoch: [0][20/2004]\tLoss 5.7513\t\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "Epoch: [0][30/2004]\tLoss 8.3919\t\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "Epoch: [0][40/2004]\tLoss 11.5383\t\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "Epoch: [0][50/2004]\tLoss 14.8206\t\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "Epoch: [0][60/2004]\tLoss 18.5342\t\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "Epoch: [0][70/2004]\tLoss 21.3360\t\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "Epoch: [0][80/2004]\tLoss 24.1953\t\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "Epoch: [0][90/2004]\tLoss 27.5294\t\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "Epoch: [0][100/2004]\tLoss 30.3957\t\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "Epoch: [0][110/2004]\tLoss 33.6202\t\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "Epoch: [0][120/2004]\tLoss 36.0786\t\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "Epoch: [0][130/2004]\tLoss 38.7358\t\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "Epoch: [0][140/2004]\tLoss 42.0336\t\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "Epoch: [0][150/2004]\tLoss 44.6397\t\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "Epoch: [0][160/2004]\tLoss 47.5875\t\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "Epoch: [0][170/2004]\tLoss 50.6154\t\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "Epoch: [0][180/2004]\tLoss 53.2247\t\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "Epoch: [0][190/2004]\tLoss 56.0243\t\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "Epoch: [0][200/2004]\tLoss 58.2119\t\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "Epoch: [0][210/2004]\tLoss 60.9052\t\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "Epoch: [0][220/2004]\tLoss 63.8903\t\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "Epoch: [0][230/2004]\tLoss 66.7045\t\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "Epoch: [0][240/2004]\tLoss 69.3652\t\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "Epoch: [0][250/2004]\tLoss 72.5769\t\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "Epoch: [0][260/2004]\tLoss 74.8828\t\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n",
      "False [300, 300]\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "print(\"Start train.\")\n",
    "train_model(net, train_loader, val_loader, optimizer, args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
