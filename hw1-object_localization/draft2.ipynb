{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b96597e-2e64-4f33-b4d8-15a1c900766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import warnings\n",
    "#warnings.filterwarnings('error')\n",
    "# with warnings.catch_warnings():\n",
    "#     warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "    \n",
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torch.nn.parameter import Parameter\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# imports\n",
    "from wsddn import WSDDN\n",
    "from voc_dataset import *\n",
    "import wandb\n",
    "from utils import nms, tensor_to_PIL\n",
    "from PIL import Image, ImageDraw\n",
    "import sklearn.metrics\n",
    "from utils import *\n",
    "#\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fad5dd-89ca-4b58-99e8-4969dfd0d440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "# ------------\n",
    "parser = argparse.ArgumentParser(description='PyTorch ImageNet Training')\n",
    "parser.add_argument(\n",
    "    '--lr',\n",
    "    default=0.0001,\n",
    "    type=float,\n",
    "    help='Learning rate'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--lr-decay-steps',\n",
    "    default=150000,\n",
    "    type=int,\n",
    "    help='Interval at which the lr is decayed'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--lr-decay',\n",
    "    default=0.1,\n",
    "    type=float,\n",
    "    help='Decay rate of lr'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--momentum',\n",
    "    default=0.9,\n",
    "    type=float,\n",
    "    help='Momentum of optimizer'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--weight-decay',\n",
    "    default=0.0005,\n",
    "    type=float,\n",
    "    help='Weight decay'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--epochs',\n",
    "    default=5,\n",
    "    type=int,\n",
    "    help='Number of epochs'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--val-interval',\n",
    "    default=5000,\n",
    "    type=int,\n",
    "    help='Interval at which to perform validation'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--disp-interval',\n",
    "    default=10,\n",
    "    type=int,\n",
    "    help='Interval at which to perform visualization'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--use-wandb',\n",
    "    default=True,\n",
    "    type=bool,\n",
    "    help='Flag to enable visualization'\n",
    ")\n",
    "\n",
    "class args:\n",
    "    parsed_args = parser.parse_known_args()[0]\n",
    "    batch_size = 2\n",
    "    workers = 2\n",
    "    disp_interval = parsed_args.disp_interval\n",
    "    val_interval= parsed_args.val_interval\n",
    "    epochs = parsed_args.epochs\n",
    "    lr= parsed_args.lr\n",
    "    use_wandb = parsed_args.use_wandb\n",
    "    pretrained = True\n",
    "    momentum = parsed_args.momentum\n",
    "    weight_decay = parsed_args.weight_decay\n",
    "    #start_epoch = parsed_args.start_epoch\n",
    "print(args.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df7a257-5ac3-4d2e-8443-0659f4912a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "global args\n",
    "# TODO (Q2.2): Load datasets and create dataloaders\n",
    "dataset = VOCDataset('trainval', top_n=300, image_size=512, data_dir='./data/VOCdevkit/VOC2007/')\n",
    "n = len(dataset)\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [int(np.floor(n*0.8)), n-int(np.floor(n*0.8))])\n",
    "train_sampler = torch.utils.data.SubsetRandomSampler(range(len(train_dataset)))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=args.workers,\n",
    "    pin_memory=True,\n",
    "    sampler=train_sampler,\n",
    "    collate_fn=custom_collate_fn_VOC,\n",
    "    drop_last=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=args.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=args.workers,\n",
    "    pin_memory=True,\n",
    "    collate_fn=custom_collate_fn_VOC,\n",
    "    drop_last=True)\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "# Initialize wandb logger\n",
    "if args.use_wandb:\n",
    "    wandb.init(project=\"vlr-hw1(task2)\", reinit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e857e6a4-764f-44b3-9aa5-bc66711dacb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "rand_seed = 1024\n",
    "if rand_seed is not None:\n",
    "    np.random.seed(rand_seed)\n",
    "    torch.manual_seed(rand_seed)\n",
    "\n",
    "# Set output directory\n",
    "output_dir = \"./\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "def metric1(output, target):\n",
    "    # TODO (Q1.5): compute metric1\n",
    "    target = target.detach().numpy().astype('int')\n",
    "    output = output.detach().numpy().astype('float')\n",
    "    # get features that aren't all zero\n",
    "    feat_considered = ~np.all(np.concatenate([target, output]), axis=0)\n",
    "    mean_ap = sklearn.metrics.average_precision_score(target[:,feat_considered], output[:,feat_considered], average='samples')\n",
    "    return mean_ap    #[0]\n",
    "\n",
    "def calculate_map(roi_bboxes, box_scores,  gt_classes, gt_bboxes, n_classes=20):\n",
    "    \"\"\"\n",
    "    Calculate the mAP for classification.\n",
    "    #        \n",
    "    \"\"\"\n",
    "    # TODO (Q2.3): Calculate mAP on test set.\n",
    "    # Using IOU to iterate each box for each class\n",
    "    # Compare each iteratively and take Maximum IOU\n",
    "    pred_boxes, gt_boxes = np.asarray(roi_bboxes), np.asarray(gt_bboxes)\n",
    "    per_class_iou = np.zeros(n_classes)   # ( 20)\n",
    "    filtered_bboxes = []\n",
    "    cls_labels = []\n",
    "    for class_num in range(20):   # (per class)\n",
    "        gt_class_idx = np.where(np.asarray(gt_classes)==class_num)[0]\n",
    "        pred_class_idx = np.where(np.argmax(np.asarray(roi_bboxes), axis=1)==class_num)[0]\n",
    "        if len(pred_class_idx)==0 or len(gt_class_idx)==0:\n",
    "            per_class_iou[class_num] = 0\n",
    "            continue\n",
    "        pred_class_bbox, gt_class_bbox = pred_boxes[pred_class_idx], gt_boxes[gt_class_idx]\n",
    "        #\n",
    "        bboxes, conf_scores = nms(pred_class_bbox, box_scores[pred_class_idx])\n",
    "        filtered_bboxes.append(bboxes)\n",
    "        cls_labels += [class_num]*len(bboxes)\n",
    "        # iterate each bbox to gt bbox\n",
    "        class_iou = []\n",
    "        for i, pred_box in enumerate(pred_class_bbox):\n",
    "            class_iou.append(np.max([iou(pred_box, gt_box) for gt_box in gt_class_bbox]))\n",
    "        per_class_iou[class_num] = np.array(class_iou).mean()\n",
    "    return per_class_iou, (filtered_bboxes, cls_labels)\n",
    "\n",
    "\n",
    "def test_model(model, val_loader=None, thresh=0.05):\n",
    "    \"\"\"\n",
    "    Tests the networks and visualizes the detections\n",
    "    :param thresh: Confidence threshold\n",
    "    \"\"\"\n",
    "    test_loss = 0\n",
    "    class_id_to_label = dict(enumerate(dataset.CLASS_NAMES))\n",
    "    class_ap_table = wandb.Table(columns=dataset.CLASS_NAMES)\n",
    "    vis_table = wandb.Table(columns=[\"image\", \"prediction\", \"mean class scores\"])\n",
    "    batch_class_ap = []\n",
    "    #\n",
    "    with torch.no_grad():\n",
    "        batch_ap_by_class = []\n",
    "        for i, data in enumerate(val_loader):\n",
    "            # one batch = data for one image\n",
    "            image = data['image']\n",
    "            target = data['label']\n",
    "            wgt = data['wgt']\n",
    "            rois = data['rois']\n",
    "            gt_boxes = data['gt_boxes']\n",
    "            gt_class = data['gt_classes']\n",
    "            for r in rois:\n",
    "                if len(r)!= 300:\n",
    "                    continue\n",
    "            img_info = dict.fromkeys(np.arange(args.batch_size), {'pred_boxes':[],'pred_cls':[]})\n",
    "            # TODO (Q2.3): perform forward pass, compute cls_probs\n",
    "            cls_prob = model(image, rois, target)   # (N, 300, 20)\n",
    "            \n",
    "            loss = model.build_loss(cls_prob, target)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # TODO (Q2.3): Iterate over each class (follow comments)\n",
    "            for n in range(args.batch_size):\n",
    "                # Get NMS bboxes\n",
    "                ap_by_class, (pred_boxes, labels) = calculate_map(rois[n], cls_prob[n].detach().cpu(),  gt_class[n], gt_boxes[n])\n",
    "                batch_class_ap.append(ap_by_class)\n",
    "                pred_boxes.append(pred_boxes)\n",
    "            running_mean_ap = np.mean(np.stack(batch_class_ap), axis=0)\n",
    "            class_ap_table.add_data(*running_mean_ap)\n",
    "            # TODO (Q2.3): visualize bounding box predictions when required\n",
    "            if i%args.val_interval==0:\n",
    "                for n, im in enumerate(image):\n",
    "                    gtbbox_img = wandb.Image(im, boxes={\n",
    "                        \"predictions\": {\n",
    "                        \"box_data\": get_box_data(data['gt_classes'][n], data['gt_boxes'][n]),\n",
    "                        \"class_labels\": class_id_to_label,       \n",
    "                        },\n",
    "                    })\n",
    "                    predbbox_img = wandb.Image(im, boxes={\n",
    "                        \"predictions\": {\n",
    "                        \"box_data\": get_box_data(img_info[n]['pred_cls'], img_info[n]['pred_boxes']),\n",
    "                        \"class_labels\": class_id_to_label,       \n",
    "                        },\n",
    "                    })\n",
    "                    vis_table.add_data(wandb.Image(im), gtbbox_img, predbbox_img)    \n",
    "        wandb.log({\"Visuals\": vis_table})\n",
    "        wandb.log({\"AP by Class\": class_ap_table})\n",
    "    return np.nanmean(np.stack(batch_class_ap), axis=0)\n",
    "            \n",
    "\n",
    "\n",
    "def train_model(model, train_loader=None, val_loader=None, optimizer=None, args=None):\n",
    "    \"\"\"\n",
    "    Trains the network, runs evaluation and visualizes the detections\n",
    "    \"\"\"\n",
    "    # Initialize training variables\n",
    "    train_loss = 0\n",
    "    step_cnt = 0\n",
    "    class_id_to_label = dict(enumerate(dataset.CLASS_NAMES))\n",
    "    class_ap_table = wandb.Table(columns=[str(c) for c in np.arange(len(dataset.CLASS_NAMES))])\n",
    "    vis_table = wandb.Table(columns=[\"image\", \"class AP scores\"])\n",
    "    for epoch in range(args.epochs):\n",
    "        for i, data in enumerate(train_loader):\n",
    "            debug=True if (epoch==0 and i==0) else False\n",
    "            # TODO (Q2.2): get one batch and perform forward pass\n",
    "            # one batch = data for one image\n",
    "            image = data['image']\n",
    "            target = data['label']\n",
    "            wgt = data['wgt']\n",
    "            rois = data['rois']\n",
    "            gt_boxes = data['gt_boxes']\n",
    "            gt_class = data['gt_classes']\n",
    "            if any([len(r)!= 300 for r in rois]):\n",
    "                continue\n",
    "            # TODO (Q2.2): perform forward pass\n",
    "            # take care that proposal values should be in pixels\n",
    "            # Convert inputs to cuda if training on GPU\n",
    "            if debug: print(f\"Input shapes: Image {image.size()}; ROIs:{[len(r) for r in rois]}; targets:{target.size()}\")\n",
    "            cls_prob = model(image, rois, target)   # (N, 300, 20)\n",
    "            if debug: print(f\"Output shape: {cls_prob.size()}\")\n",
    "            # backward pass and update\n",
    "            loss = model.loss\n",
    "            train_loss += loss.item()\n",
    "            step_cnt += 1\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # measure metrics and record loss\n",
    "            m1 = metric1(torch.sum(cls_prob,dim=1).cpu(), target.cpu())\n",
    "            wandb.log(\n",
    "                {'train/loss':loss, 'train/metric1': m1} #,  'train/metric2': m2,}\n",
    "            )\n",
    "            # TODO (Q2.2): evaluate the model every N iterations (N defined in handout)\n",
    "            # Add wandb logging wherever necessary\n",
    "            if i % args.val_interval == 0 and iter != 0:\n",
    "                print(\"Evaluating Model.\")\n",
    "                model.eval()\n",
    "                ap = test_model(model, val_loader)\n",
    "                model.train()\n",
    "            \n",
    "            # TODO (Q2.4): Perform all visualizations here\n",
    "            # The intervals for different things are defined in the handout\n",
    "            if i % args.disp_interval==0:\n",
    "                print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Loss {train_loss:.4f}\\t'.format(\n",
    "                      epoch,\n",
    "                      i,\n",
    "                      len(train_loader),\n",
    "                      train_loss=train_loss,\n",
    "                      # ap=ap,\n",
    "                  )\n",
    "                )\n",
    "                #logger.model_param_zhisto_summary(model=net, step=step)\n",
    "                pass\n",
    "                #\n",
    "            if i%args.disp_interval:\n",
    "                for n, im in enumerate(image):\n",
    "                    input_img = wandb.Image(im, boxes={\n",
    "                        \"predictions\": {\n",
    "                            \"box_data\": get_box_data(data['gt_classes'][n], data['gt_boxes'][n]),\n",
    "                            \"class_labels\": class_id_to_label,       \n",
    "                        },\n",
    "                    })\n",
    "                    # predbbox_img = wandb.Image(im, boxes={\n",
    "                    #     \"predictions\": {\n",
    "                    #     \"box_data\": get_box_data(img_info[n]['pred_boxes'], img_info[n]['pred_boxes']),\n",
    "                    #     \"class_labels\": class_id_to_label,       \n",
    "                    #     },\n",
    "                    # })\n",
    "                    vis_table.add_data(input_img, ap)\n",
    "                wandb.log({\"train/Visuals\": vis_table})\n",
    "                # wandb.log({\"AP by Class\": class_ap_table})\n",
    "    \n",
    "    # TODO (Q2.4): Plot class-wise APs\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "b999879e-6ba9-4fbb-b896-1688d888ed56",
   "metadata": {
    "tags": []
   },
   "source": [
    "test_model(net, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edad5f1-5e1b-4286-9b46-342db690f940",
   "metadata": {},
   "source": [
    "<b> Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92bab62-2caf-4deb-b568-48efab2fe414",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create network and initialize\n",
    "net = WSDDN(classes=dataset.CLASS_NAMES)\n",
    "\n",
    "if os.path.exists('pretrained_alexnet.pkl'):\n",
    "    pret_net = pkl.load(open('pretrained_alexnet.pkl', 'rb'))\n",
    "else:\n",
    "    pret_net = model_zoo.load_url(\n",
    "        'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth')\n",
    "    pkl.dump(pret_net,\n",
    "    open('pretrained_alexnet.pkl', 'wb'), pkl.HIGHEST_PROTOCOL)\n",
    "own_state = net.state_dict()\n",
    "\n",
    "for name, param in pret_net.items():\n",
    "    if name not in own_state:\n",
    "        continue\n",
    "    if isinstance(param, Parameter):\n",
    "        param = param.data\n",
    "    try:\n",
    "        own_state[name].copy_(param)\n",
    "    except:\n",
    "        print('Did not find {}'.format(name))\n",
    "        continue\n",
    "\n",
    "# Move model to GPU and set train mode\n",
    "net.load_state_dict(own_state)\n",
    "net.cuda()\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e71508e-6f2d-4501-a436-938f377ccfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (Q2.2): Freeze AlexNet layers since we are loading a pretrained model\n",
    "for param in net.features.parameters():\n",
    "    param.requires_grad = False\n",
    "# TODO (Q2.2): Create optimizer only for network parameters that are trainable\n",
    "params = list(net.parameters())\n",
    "optimizer = torch.optim.SGD(params, lr=args.lr, \n",
    "                            momentum=args.momentum, weight_decay=args.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41b729b-1bf4-4d19-9178-9238c7c9b906",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "print(\"Start train.\")\n",
    "train_model(net, train_loader, val_loader, optimizer, args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
