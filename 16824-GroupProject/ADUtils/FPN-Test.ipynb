{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "from segmentation_models.segmentation_models_pytorch.decoders.fpn import model\n",
    "import segmentation_models_pytorch as smp\n",
    "from torch import nn\n",
    "#from tests import test_loaded_weights, compare_output\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FPNclassifier(smp.FPN):\n",
    "    def __init__(self,backbone = 'timm-res2net50_14w_8s', n_classes=2, encoder_weights=None, **kwargs):\n",
    "        # https://github.com/qubvel/segmentation_models.pytorch#encoders \n",
    "        assert backbone in ['timm-res2net50_14w_8s','efficientnet-b7', 'timm-mobilenetv3_large_minimal_100',\n",
    "                            'timm-mobilenetv3_small_100']\n",
    "        activation = 'softmax' if n_classes > 2 else 'sigmoid'\n",
    "        super().__init__(backbone, in_channels=3, encoder_depth=5, decoder_merge_policy='cat', encoder_weights=encoder_weights,\n",
    "                        aux_params={'classes':n_classes, 'pooling': \"avg\", 'activation':activation})\n",
    "        # extract ffeatures only (*, 2048, 1, 1)\n",
    "        self.feat_out = torch.nn.Sequential(*list(self.classification_head.children())[:1])\n",
    "        activation = 'softmax' if n_classes > 2 else 'sigmoid'\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)[-1]\n",
    "        x = self.feat_out(x)\n",
    "        return class_out\n",
    "    \n",
    "     \n",
    "class Linknetclassifier(smp.Linknet):\n",
    "    def __init__(self, backbone = 'timm-res2net50_14w_8s', n_classes=2, encoder_weights=None, **kwargs):\n",
    "        # https://github.com/qubvel/segmentation_models.pytorch#encoders \n",
    "        assert backbone in ['timm-res2net50_14w_8s','efficientnet-b7', 'timm-mobilenetv3_large_minimal_100',\n",
    "                            'timm-mobilenetv3_small_100']\n",
    "        activation = 'softmax' if n_classes > 2 else 'sigmoid'\n",
    "        super().__init__(backbone, in_channels=3, encoder_depth=5, encoder_weights=encoder_weights,\n",
    "                        aux_params={'classes':n_classes, 'pooling': \"avg\", 'activation':activation})\n",
    "        # extract ffeatures only (*, 2048, 1, 1)\n",
    "        self.feat_out = torch.nn.Sequential(*list(self.classification_head.children())[:1])\n",
    "        activation = 'softmax' if n_classes > 2 else 'sigmoid'\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)[-1]\n",
    "        x = self.feat_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HEClassificationModel(pl.LightningModule):\n",
    "    def __init__(self, model_name:str, n_classes:int=2, pretrain:bool=True,\n",
    "                 input_size:tuple=(224,224),  log_metrics:bool=False, debug:bool=False):\n",
    "        super().__init__()\n",
    "        print(f\"Using pre-trained head:{model_name}\")\n",
    "        avail_models =  ['mobilenetv3','resnext101','efficientnetb7','resnet50','Multiscale-Linknet','Multiscale-FPN']\n",
    "        assert model_name in avail_models, f\"Must be one of {avail_models}\"\n",
    "        self.debug = debug\n",
    "        self.n_classes = n_classes\n",
    "        # Step 1: Initialize model with the weights\n",
    "        if model_name in avail_models[:4]:\n",
    "            if model_name == 'mobilenetv3':\n",
    "                self.model = models.mobilenet_v3_large(weights=MobileNet_V3_Large_Weights.IMAGENET1K_V2 if pretrain else None)\n",
    "            elif model_name == 'resnext101':\n",
    "                self.model = models.resnext101_32x8d(weights=ResNeXt101_32X8D_Weights.IMAGENET1K_V1 if pretrain else None)\n",
    "            elif model_name == 'efficientnetb7':\n",
    "                self.model = models.efficientnet_b7(weights=EfficientNet_B7_Weights.IMAGENET1K_V1 if pretrain else None)\n",
    "            elif model_name =='resnet50':\n",
    "                self.model = models.resnet50(pretrained=ResNet50_Weights.IMAGENET1K_V2 if pretrain else None)\n",
    "            # replace/remove head\n",
    "            removed = list(self.model.children())[:-1]\n",
    "            self.model_base = torch.nn.Sequential(*removed) \n",
    "        else:\n",
    "            # Model with a (*, n, 1,1) output\n",
    "            if model_name == 'Multiscale-Linknet':\n",
    "                self.model_base = Linknetclassifier(pretrained=pretrain)\n",
    "            elif model_name == 'Multiscale-FPN':\n",
    "                self.model_base = FPNclassifier(pretrained=pretrain)\n",
    "         \n",
    "        in_feats = self._get_output_feat(self.model_base, input_size)\n",
    "        # head\n",
    "        self.model_head = nn.Sequential(nn.Flatten(),\n",
    "                                        nn.Linear(in_features=in_feats, out_features=self.n_classes),\n",
    "                                        nn.LogSoftmax(dim=1) if n_classes>2 else nn.Sigmoid(),\n",
    "                                       )\n",
    "        self.model = torch.nn.Sequential(self.model_base, self.model_head)\n",
    "            #self.model_head.to(device=META_ARGS.device)     \n",
    "        # metrics\n",
    "        self.log_metrics = log_metrics\n",
    "        self.sync_dist = True\n",
    "        if log_metrics:\n",
    "            self.metric_device = 'cpu'\n",
    "            self.accuracy = torchmetrics.Accuracy().to(self.metric_device)\n",
    "            self.recall = torchmetrics.Recall(average='macro', num_classes=2).to(self.metric_device)\n",
    "            #self.ROC = torchmetrics.ROC(num_classes=n_classes)\n",
    "            self.AUROC = torchmetrics.AUROC(num_classes=n_classes, pos_label=1).to(self.metric_device)\n",
    "\n",
    "    def _get_output_feat(self, model, in_shape=(224,224)):\n",
    "        x = torch.randn((3,)+in_shape)\n",
    "        return model(x.unsqueeze(0)).flatten().size()[0]\n",
    "\n",
    "    def _forward_feature_extract(self, x):\n",
    "        return self.model_base(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        if self.debug: print(f\"Num classes:{self.n_classes}\\nModel classifier\\n:{self.model_head}\")\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3, weight_decay=1e-10)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1e5)\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    def get_loss(self, y_hat, y):\n",
    "        #loss = nn.CrossEntropyLoss()   # does softmax for you (no need in classifcation)\n",
    "        #loss = nn.LogSoftmax()\n",
    "        #loss = F.nll_loss\n",
    "        if self.debug: print(y.size(), y.dtype, y_hat.size(), y_hat.dtype)\n",
    "        return F.cross_entropy(y_hat,  y)\n",
    "\n",
    "    def training_step(self, batch, batch_idx=None):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.get_loss(y_hat, y)\n",
    "        # training metrics\n",
    "        \n",
    "        # optimize (done under the hoood)\n",
    "        if self.log_metrics:\n",
    "            acc = self.accuracy(torch.argmax(y_hat, dim=1).to(self.metric_device), y.to(self.metric_device))\n",
    "            self.log('train_loss', loss, on_step=True, on_epoch=True, logger=True, sync_dist=self.sync_dist)\n",
    "            self.log('train_acc', acc, on_step=True, on_epoch=True, logger=True, sync_dist=self.sync_dist)\n",
    "        return loss\n",
    "        #return self.get_loss(y, y_hat)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx=None):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        # compute metrics\n",
    "        val_loss =self.get_loss(y_hat, y)\n",
    "        if self.log_metrics:\n",
    "            acc = self.accuracy(torch.argmax(y_hat, dim=1).to(self.metric_device).detach(), y.to(self.metric_device).detach())\n",
    "            #auroc = self.AUROC(y_hat.to(self.metric_device), y.to(self.metric_device))\n",
    "            #fpr, tpr, thresholds = self.ROC(y_hat, y)\n",
    "\n",
    "            self.log(\"val_loss\", val_loss)\n",
    "            self.log('val_acc', acc, on_step=True, on_epoch=True, logger=True, sync_dist=self.sync_dist)\n",
    "            #self.AUROC.update(y_hat.cpu().detach(), y.cpu().detach())\n",
    "            #self.log(\"validation_auc\", self.AUROC, on_step=False, on_epoch=True, sync_dist=self.sync_dist)   # prog_bar=True,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pre-trained head:Multiscale-FPN\n"
     ]
    }
   ],
   "source": [
    "#model = FPNclassifier(pretrained=True)  #\n",
    "model = HEClassificationModel(model_name='Multiscale-FPN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2048, 1, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((3,3,1120,1120))\n",
    "model(x).size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "vision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
